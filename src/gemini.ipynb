{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68625e04",
   "metadata": {},
   "source": [
    "# USE GEMINI TO LABEL STUDENT PREFERENCES ACCORDING TO TOPICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9b509",
   "metadata": {},
   "source": [
    "## Import supervisor list and remove duplicate topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e3c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def import_supervisors(file_path):\n",
    "    supervisors = []\n",
    "    try:\n",
    "        with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "            csv_reader = csv.DictReader(file)\n",
    "            for row in csv_reader:\n",
    "                supervisors.append(row)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "    return supervisors  \n",
    "\n",
    "\n",
    "def supervisors_to_dataframe(supervisors_csv):\n",
    "    try:\n",
    "        df = pd.DataFrame(supervisors_csv)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while converting to DataFrame: {e}\")\n",
    "        return None \n",
    "    \n",
    "\n",
    "def combine_expertise_topics(row, expertise_columns):\n",
    "    \"\"\"Helper function to combine topics from multiple expertise areas\"\"\"\n",
    "    all_topics = []\n",
    "    for col in expertise_columns:\n",
    "        if row[col]:\n",
    "            # Handle if input is already a list or string\n",
    "            topics = row[col] if isinstance(row[col], list) else eval(str(row[col]))\n",
    "            # Clean each topic in the list\n",
    "            cleaned_topics = [t.strip() for t in topics if t.strip()]\n",
    "            all_topics.extend(cleaned_topics)\n",
    "    # Remove duplicates while preserving order\n",
    "    unique_topics = list(dict.fromkeys(all_topics))\n",
    "    return ', '.join(unique_topics)\n",
    "\n",
    "# Generate supervisor ID and a randomised capacity\n",
    "# Add a 'topics' column that is baed on the 'Expertise Area 1', 'Expertise Area 2', and 'Expertise Area 3' columns\n",
    "def generate_supervisor_data(supervisors_df):\n",
    "    if supervisors_df is None or supervisors_df.empty:\n",
    "        print(\"No data to process.\")\n",
    "        return None\n",
    "\n",
    "    supervisors_df['supervisor_id'] = range(1, len(supervisors_df) + 1)\n",
    "    \n",
    "    import random\n",
    "    supervisors_df['capacity'] = [random.randint(3, 10) for _ in range(len(supervisors_df))]\n",
    "    \n",
    "    expertise_columns = ['Expertise Area 1', 'Expertise Area 2', 'Expertise Area 3']\n",
    "    supervisors_df['topics'] = supervisors_df.apply(\n",
    "        lambda x: combine_expertise_topics(x, expertise_columns), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return supervisors_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f71d24",
   "metadata": {},
   "source": [
    "## Use Gemini to standardise supervisor topics for easier labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef63c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame sample:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seanh\\Documents\\University\\CAPSTONE 2\\CAPSTONE-2\\.env_capstone\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Preferred Programme for Supervision (1st Choice)</th>\n",
       "      <th>Preferred Programme for Supervision (2nd Choice)</th>\n",
       "      <th>Expertise Area 1</th>\n",
       "      <th>Expertise Area 2</th>\n",
       "      <th>Expertise Area 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali Afzalian Mand</td>\n",
       "      <td>DDSAI</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>[Machine Learning Theory]</td>\n",
       "      <td>[AI for Healthcare]</td>\n",
       "      <td>[Deep Learning, Neural Networks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assoc. Prof. Dr Anwar P.P. Abdul Majeed</td>\n",
       "      <td>DDSAI</td>\n",
       "      <td>BSDA</td>\n",
       "      <td>BCS / BSE / BIT</td>\n",
       "      <td>[Machine Learning, Deep Learning]</td>\n",
       "      <td>[Data Analytics]</td>\n",
       "      <td>[Robotics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assoc. Prof. Dr Azam Che Idris</td>\n",
       "      <td>DDSAI</td>\n",
       "      <td>BSDA</td>\n",
       "      <td>BCS / BSE / BIT</td>\n",
       "      <td>[DEEP LEARNING, MACHINE LEARNING]</td>\n",
       "      <td>[TIME SERIES ANALYSIS]</td>\n",
       "      <td>[COMPUTER VISION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assoc. Prof. Dr Muhammed Basheer Jasser</td>\n",
       "      <td>DDSAI</td>\n",
       "      <td>BCS / BSE / BIT</td>\n",
       "      <td>BSDA</td>\n",
       "      <td>[Machine Learning, Artificial Intelligence]</td>\n",
       "      <td>[Swarm and Evolutionary Computing]</td>\n",
       "      <td>[Software Engineering, Software Modeling]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc. Prof. Dr Aslina Baharum</td>\n",
       "      <td>DDSAI</td>\n",
       "      <td>BCS / BSE / BIT</td>\n",
       "      <td>BSDA</td>\n",
       "      <td>[AI-UX, UX/UI Research &amp; Design, HCI, Interact...</td>\n",
       "      <td>[Software Engineering &amp; Development, Informati...</td>\n",
       "      <td>[Information and Communication Technology (ICT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name Department  \\\n",
       "0                        Ali Afzalian Mand      DDSAI   \n",
       "1  Assoc. Prof. Dr Anwar P.P. Abdul Majeed      DDSAI   \n",
       "2           Assoc. Prof. Dr Azam Che Idris      DDSAI   \n",
       "3  Assoc. Prof. Dr Muhammed Basheer Jasser      DDSAI   \n",
       "4           Assoc. Prof. Dr Aslina Baharum      DDSAI   \n",
       "\n",
       "  Preferred Programme for Supervision (1st Choice)  \\\n",
       "0                                    No Preference   \n",
       "1                                             BSDA   \n",
       "2                                             BSDA   \n",
       "3                                  BCS / BSE / BIT   \n",
       "4                                  BCS / BSE / BIT   \n",
       "\n",
       "  Preferred Programme for Supervision (2nd Choice)  \\\n",
       "0                                    No Preference   \n",
       "1                                  BCS / BSE / BIT   \n",
       "2                                  BCS / BSE / BIT   \n",
       "3                                             BSDA   \n",
       "4                                             BSDA   \n",
       "\n",
       "                                    Expertise Area 1  \\\n",
       "0                          [Machine Learning Theory]   \n",
       "1                  [Machine Learning, Deep Learning]   \n",
       "2                  [DEEP LEARNING, MACHINE LEARNING]   \n",
       "3        [Machine Learning, Artificial Intelligence]   \n",
       "4  [AI-UX, UX/UI Research & Design, HCI, Interact...   \n",
       "\n",
       "                                    Expertise Area 2  \\\n",
       "0                                [AI for Healthcare]   \n",
       "1                                   [Data Analytics]   \n",
       "2                             [TIME SERIES ANALYSIS]   \n",
       "3                 [Swarm and Evolutionary Computing]   \n",
       "4  [Software Engineering & Development, Informati...   \n",
       "\n",
       "                                    Expertise Area 3  \n",
       "0                   [Deep Learning, Neural Networks]  \n",
       "1                                         [Robotics]  \n",
       "2                                  [COMPUTER VISION]  \n",
       "3          [Software Engineering, Software Modeling]  \n",
       "4  [Information and Communication Technology (ICT...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 116 unique expertise terms to standardise:\n",
      "['AI', 'AI applications in Robotics', 'AI for Healthcare', 'AI-UX', 'AR', 'Agentic AI', 'Antenna Design', 'Application Development', 'Application development', 'Applied AI', 'Applied Generative AI', 'Applied Machine Learning', 'Applied machine learning', 'Artificial Intelligence', 'Automated Test and Measurement Systems', 'Battery Energy Storage Management', 'Big Data Analysis', 'Blockchain', 'COMPUTER VISION', 'Chatbots', 'Cloud Computing', 'Clustering Algorithms & Optimization', 'Commercial Projects', 'Computational Intelligence', 'Computer Engineering', 'Computer Graphic', 'Computer Networking', 'Computer Networks', 'Computer Science', 'Computer Vision', 'Computer Vision & Image Processing', 'Computing study with qualitative & quantitative data (survey,interview)', 'Cybersecurity', 'DEEP LEARNING', 'Data Analytics', 'Data Mining', 'Databases', 'Deep Learning', 'Deep learning', 'Development', 'Digital Image Processing', 'Distributed System', 'Distributed haptics', 'E-commerce games', 'Electronics', 'Embedded System', 'Embedded System Development', 'Embedded system applications', 'Embeded Systems', 'Environment', 'Extended reality (VR,AR,MR)', 'Fiber Optic Sensor', 'GenAI', 'Generative AI Usage Ethics', 'Green computing', 'HCI', 'High-speed computer and Telecommunications networks', 'Image Processing', 'Image and computer vision', 'Industrial IoT', 'Information Security', 'Information System', 'Information Visualization & Analytics', 'Information and Communication Technology (ICT)/ Information Technology (IT)/ Multimedia/ Information System (IS)', 'Interaction Design', 'Internet of Things (IoT)', 'IoT', 'IoT Applications', 'MACHINE LEARNING', 'Machine', 'Machine Learning', 'Machine Learning Theory', 'Machine Learning\\\\Deep learning', 'Machine learning', 'Mining', 'Mixed Reality', 'Mobile Application Development', 'Mobile Cellular Networks', 'Nanomaterial for Ultrashort Fiber Laser', 'Natural Language Processing', 'Network', 'Network Coding', 'Network Security', 'Network architectures and protocols', 'Neural Networks', 'Neuroscience', 'Operational optimisation for sustainability', 'Pattern Recognition', 'Photonic Devices', 'Product/Service Design', 'Qualitative study', 'Renewable Energy System Management', 'Robotics', 'Signal Processing', 'Smart transportation system', 'Software Engineering', 'Software Engineering & Development', 'Software Modeling', 'Statistical methods in data science', 'Sustainable smart city', 'Swarm and Evolutionary Computing', 'TIME SERIES ANALYSIS', 'Time Series Analysis', 'TinyML', 'UI and UX', 'UX/UI Research & Design', 'Ultrasound Indoor Localization', 'VR', 'Wireless Communication', 'Wireless Networks', 'data analytics', 'deep learning', 'distributed systems', 'health', 'mobile development', 'signal processing']\n",
      "Sending request to Gemini API...\n",
      "\n",
      "--- standardisation Map from Gemini (Review this carefully!) ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"AI\": \"Artificial Intelligence\",\n",
       "  \"AI applications in Robotics\": \"Robotics\",\n",
       "  \"AI for Healthcare\": \"AI for Healthcare\",\n",
       "  \"AI-UX\": \"UX/UI Design\",\n",
       "  \"AR\": \"Augmented Reality\",\n",
       "  \"Agentic AI\": \"Artificial Intelligence\",\n",
       "  \"Antenna Design\": \"Antenna Design\",\n",
       "  \"Application Development\": \"Application Development\",\n",
       "  \"Application development\": \"Application Development\",\n",
       "  \"Applied AI\": \"Artificial Intelligence\",\n",
       "  \"Applied Generative AI\": \"Generative AI\",\n",
       "  \"Applied Machine Learning\": \"Machine Learning\",\n",
       "  \"Applied machine learning\": \"Machine Learning\",\n",
       "  \"Artificial Intelligence\": \"Artificial Intelligence\",\n",
       "  \"Automated Test and Measurement Systems\": \"Automated Test and Measurement Systems\",\n",
       "  \"Battery Energy Storage Management\": \"Renewable Energy System Management\",\n",
       "  \"Big Data Analysis\": \"Data Analytics\",\n",
       "  \"Blockchain\": \"Blockchain\",\n",
       "  \"COMPUTER VISION\": \"Computer Vision\",\n",
       "  \"Chatbots\": \"Natural Language Processing\",\n",
       "  \"Cloud Computing\": \"Cloud Computing\",\n",
       "  \"Clustering Algorithms & Optimization\": \"Clustering Algorithms & Optimization\",\n",
       "  \"Commercial Projects\": \"Commercial Projects\",\n",
       "  \"Computational Intelligence\": \"Artificial Intelligence\",\n",
       "  \"Computer Engineering\": \"Computer Engineering\",\n",
       "  \"Computer Graphic\": \"Computer Graphics\",\n",
       "  \"Computer Networking\": \"Computer Networking\",\n",
       "  \"Computer Networks\": \"Computer Networking\",\n",
       "  \"Computer Science\": \"Computer Science\",\n",
       "  \"Computer Vision\": \"Computer Vision\",\n",
       "  \"Computer Vision & Image Processing\": \"Computer Vision\",\n",
       "  \"Computing study with qualitative & quantitative data (survey,interview)\": \"Qualitative Research\",\n",
       "  \"Cybersecurity\": \"Cybersecurity\",\n",
       "  \"DEEP LEARNING\": \"Deep Learning\",\n",
       "  \"Data Analytics\": \"Data Analytics\",\n",
       "  \"Data Mining\": \"Data Mining\",\n",
       "  \"Databases\": \"Databases\",\n",
       "  \"Deep Learning\": \"Deep Learning\",\n",
       "  \"Deep learning\": \"Deep Learning\",\n",
       "  \"Development\": \"Software Engineering\",\n",
       "  \"Digital Image Processing\": \"Image Processing\",\n",
       "  \"Distributed System\": \"Distributed Systems\",\n",
       "  \"Distributed haptics\": \"Distributed Haptics\",\n",
       "  \"E-commerce games\": \"E-commerce games\",\n",
       "  \"Electronics\": \"Electronics\",\n",
       "  \"Embedded System\": \"Embedded Systems\",\n",
       "  \"Embedded System Development\": \"Embedded Systems\",\n",
       "  \"Embedded system applications\": \"Embedded Systems\",\n",
       "  \"Embeded Systems\": \"Embedded Systems\",\n",
       "  \"Environment\": \"Environment\",\n",
       "  \"Extended reality (VR,AR,MR)\": \"Extended Reality\",\n",
       "  \"Fiber Optic Sensor\": \"Fiber Optic Sensor\",\n",
       "  \"GenAI\": \"Generative AI\",\n",
       "  \"Generative AI Usage Ethics\": \"Generative AI\",\n",
       "  \"Green computing\": \"Green Computing\",\n",
       "  \"HCI\": \"Human-Computer Interaction\",\n",
       "  \"High-speed computer and Telecommunications networks\": \"Computer Networking\",\n",
       "  \"Image Processing\": \"Image Processing\",\n",
       "  \"Image and computer vision\": \"Computer Vision\",\n",
       "  \"Industrial IoT\": \"Internet of Things\",\n",
       "  \"Information Security\": \"Cybersecurity\",\n",
       "  \"Information System\": \"Information Systems\",\n",
       "  \"Information Visualization & Analytics\": \"Information Visualization\",\n",
       "  \"Information and Communication Technology (ICT)/ Information Technology (IT)/ Multimedia/ Information System (IS)\": \"Information Technology\",\n",
       "  \"Interaction Design\": \"Interaction Design\",\n",
       "  \"Internet of Things (IoT)\": \"Internet of Things\",\n",
       "  \"IoT\": \"Internet of Things\",\n",
       "  \"IoT Applications\": \"Internet of Things\",\n",
       "  \"MACHINE LEARNING\": \"Machine Learning\",\n",
       "  \"Machine\": \"Machine Learning\",\n",
       "  \"Machine Learning\": \"Machine Learning\",\n",
       "  \"Machine Learning Theory\": \"Machine Learning\",\n",
       "  \"Machine Learning\\\\Deep learning\": \"Deep Learning\",\n",
       "  \"Machine learning\": \"Machine Learning\",\n",
       "  \"Mining\": \"Data Mining\",\n",
       "  \"Mixed Reality\": \"Mixed Reality\",\n",
       "  \"Mobile Application Development\": \"Mobile Development\",\n",
       "  \"Mobile Cellular Networks\": \"Wireless Communication\",\n",
       "  \"Nanomaterial for Ultrashort Fiber Laser\": \"Nanomaterials\",\n",
       "  \"Natural Language Processing\": \"Natural Language Processing\",\n",
       "  \"Network\": \"Computer Networking\",\n",
       "  \"Network Coding\": \"Network Coding\",\n",
       "  \"Network Security\": \"Network Security\",\n",
       "  \"Network architectures and protocols\": \"Computer Networking\",\n",
       "  \"Neural Networks\": \"Neural Networks\",\n",
       "  \"Neuroscience\": \"Neuroscience\",\n",
       "  \"Operational optimisation for sustainability\": \"Operational Optimisation\",\n",
       "  \"Pattern Recognition\": \"Pattern Recognition\",\n",
       "  \"Photonic Devices\": \"Photonic Devices\",\n",
       "  \"Product/Service Design\": \"Product Design\",\n",
       "  \"Qualitative study\": \"Qualitative Research\",\n",
       "  \"Renewable Energy System Management\": \"Renewable Energy System Management\",\n",
       "  \"Robotics\": \"Robotics\",\n",
       "  \"Signal Processing\": \"Signal Processing\",\n",
       "  \"Smart transportation system\": \"Smart Cities\",\n",
       "  \"Software Engineering\": \"Software Engineering\",\n",
       "  \"Software Engineering & Development\": \"Software Engineering\",\n",
       "  \"Software Modeling\": \"Software Engineering\",\n",
       "  \"Statistical methods in data science\": \"Data Science\",\n",
       "  \"Sustainable smart city\": \"Smart Cities\",\n",
       "  \"Swarm and Evolutionary Computing\": \"Swarm and Evolutionary Computing\",\n",
       "  \"TIME SERIES ANALYSIS\": \"Time Series Analysis\",\n",
       "  \"Time Series Analysis\": \"Time Series Analysis\",\n",
       "  \"TinyML\": \"Embedded Systems\",\n",
       "  \"UI and UX\": \"UX/UI Design\",\n",
       "  \"UX/UI Research & Design\": \"UX/UI Design\",\n",
       "  \"Ultrasound Indoor Localization\": \"Ultrasound Indoor Localization\",\n",
       "  \"VR\": \"Virtual Reality\",\n",
       "  \"Wireless Communication\": \"Wireless Communication\",\n",
       "  \"Wireless Networks\": \"Wireless Communication\",\n",
       "  \"data analytics\": \"Data Analytics\",\n",
       "  \"deep learning\": \"Deep Learning\",\n",
       "  \"distributed systems\": \"Distributed Systems\",\n",
       "  \"health\": \"Healthcare\",\n",
       "  \"mobile development\": \"Mobile Development\",\n",
       "  \"signal processing\": \"Signal Processing\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying standardisation map to DataFrame...\n",
      "0                                    [Machine Learning]\n",
      "1                     [Machine Learning, Deep Learning]\n",
      "2                     [Deep Learning, Machine Learning]\n",
      "3           [Machine Learning, Artificial Intelligence]\n",
      "4     [UX/UI Design, UX/UI Design, Human-Computer In...\n",
      "5               [Neuroscience, Healthcare, Environment]\n",
      "6                     [Deep Learning, Machine Learning]\n",
      "7                             [Artificial Intelligence]\n",
      "8                                     [Computer Vision]\n",
      "9                             [Artificial Intelligence]\n",
      "10    [Mixed Reality, Augmented Reality, Virtual Rea...\n",
      "11                            [Artificial Intelligence]\n",
      "12                                   [Machine Learning]\n",
      "13                                        [Data Mining]\n",
      "14                            [Artificial Intelligence]\n",
      "15    [Virtual Reality, Augmented Reality, Computer ...\n",
      "16                            [Artificial Intelligence]\n",
      "17    [Machine Learning, Deep Learning, Artificial I...\n",
      "18    [Wireless Communication, Wireless Communicatio...\n",
      "19                                     [Data Analytics]\n",
      "20    [Artificial Intelligence, Generative AI, Artif...\n",
      "21                                    [Computer Vision]\n",
      "22                            [Artificial Intelligence]\n",
      "23                                         [Blockchain]\n",
      "24                                      [Cybersecurity]\n",
      "25                                [Information Systems]\n",
      "26                                    [Computer Vision]\n",
      "27                                   [Embedded Systems]\n",
      "28                               [Software Engineering]\n",
      "29                    [Machine Learning, Deep Learning]\n",
      "30                                   [Photonic Devices]\n",
      "31                                [Computer Networking]\n",
      "32                                     [Data Analytics]\n",
      "33                                [Information Systems]\n",
      "34                            [Artificial Intelligence]\n",
      "35                                [Computer Networking]\n",
      "36                                     [Data Analytics]\n",
      "37                                   [Extended Reality]\n",
      "38                                    [Green Computing]\n",
      "39                  [Computer Engineering, Electronics]\n",
      "40                                   [E-commerce games]\n",
      "41                                   [Embedded Systems]\n",
      "42                               [Software Engineering]\n",
      "43                 [Renewable Energy System Management]\n",
      "44             [Generative AI, Artificial Intelligence]\n",
      "45                                [Distributed Haptics]\n",
      "46                                 [Mobile Development]\n",
      "47                            [Application Development]\n",
      "48                                       [Smart Cities]\n",
      "49                             [Wireless Communication]\n",
      "50                                     [Data Analytics]\n",
      "51                                                   []\n",
      "52    [Distributed Systems, Internet of Things, Data...\n",
      "Name: standardised Expertise 1, dtype: object\n",
      "0                                   [AI for Healthcare]\n",
      "1                                      [Data Analytics]\n",
      "2                                [Time Series Analysis]\n",
      "3                    [Swarm and Evolutionary Computing]\n",
      "4     [Software Engineering, Information Visualization]\n",
      "5                                       [Deep Learning]\n",
      "6                                    [Image Processing]\n",
      "7                                  [Internet of Things]\n",
      "8                     [Deep Learning, Machine Learning]\n",
      "9                                  [Internet of Things]\n",
      "10                                 [Internet of Things]\n",
      "11                                     [Data Analytics]\n",
      "12                            [Artificial Intelligence]\n",
      "13                                   [Machine Learning]\n",
      "14                                   [Image Processing]\n",
      "15           [UX/UI Design, Human-Computer Interaction]\n",
      "16                                     [Data Analytics]\n",
      "17                                                   []\n",
      "18                                   [Machine Learning]\n",
      "19                                       [Data Science]\n",
      "20                       [Robotics, Internet of Things]\n",
      "21                                   [Machine Learning]\n",
      "22                               [Software Engineering]\n",
      "23                                                   []\n",
      "24                                [Computer Networking]\n",
      "25                               [Qualitative Research]\n",
      "26             [Artificial Intelligence, Deep Learning]\n",
      "27                     [Ultrasound Indoor Localization]\n",
      "28                                [Distributed Systems]\n",
      "29                                   [Image Processing]\n",
      "30                                 [Fiber Optic Sensor]\n",
      "31                            [Artificial Intelligence]\n",
      "32                                   [Machine Learning]\n",
      "33                               [Qualitative Research]\n",
      "34                                 [Internet of Things]\n",
      "35                                      [Cybersecurity]\n",
      "36                                        [Data Mining]\n",
      "37                            [Application Development]\n",
      "38                                   [Machine Learning]\n",
      "39                [Signal Processing, Image Processing]\n",
      "40                        [Natural Language Processing]\n",
      "41                                   [Embedded Systems]\n",
      "42                                                   []\n",
      "43                 [Renewable Energy System Management]\n",
      "44                                   [Machine Learning]\n",
      "45                                [Computer Networking]\n",
      "46                        [Natural Language Processing]\n",
      "47                                   [Image Processing]\n",
      "48                           [Operational Optimisation]\n",
      "49                                     [Network Coding]\n",
      "50                                                   []\n",
      "51                                                   []\n",
      "52                                                   []\n",
      "Name: standardised Expertise 2, dtype: object\n",
      "0                 [Deep Learning, Neural Networks]\n",
      "1                                       [Robotics]\n",
      "2                                [Computer Vision]\n",
      "3     [Software Engineering, Software Engineering]\n",
      "4       [Information Technology, Computer Science]\n",
      "5             [Computer Vision, Signal Processing]\n",
      "6                            [Pattern Recognition]\n",
      "7                             [Mobile Development]\n",
      "8                           [Time Series Analysis]\n",
      "9                                  [Deep Learning]\n",
      "10                                              []\n",
      "11     [Artificial Intelligence, Machine Learning]\n",
      "12                                [Data Analytics]\n",
      "13                                              []\n",
      "14                                              []\n",
      "15                              [Machine Learning]\n",
      "16                              [Machine Learning]\n",
      "17                                              []\n",
      "18          [Clustering Algorithms & Optimization]\n",
      "19                       [Artificial Intelligence]\n",
      "20                            [Internet of Things]\n",
      "21                                [Data Analytics]\n",
      "22                              [Machine Learning]\n",
      "23                                              []\n",
      "24                                              []\n",
      "25                                              []\n",
      "26                                 [Generative AI]\n",
      "27        [Automated Test and Measurement Systems]\n",
      "28                          [Software Engineering]\n",
      "29                   [Data Analytics, Data Mining]\n",
      "30                                 [Nanomaterials]\n",
      "31                                              []\n",
      "32                                              []\n",
      "33                                              []\n",
      "34                                              []\n",
      "35                          [Software Engineering]\n",
      "36                                    [Blockchain]\n",
      "37                              [Machine Learning]\n",
      "38                                  [Smart Cities]\n",
      "39                          [Software Engineering]\n",
      "40                                              []\n",
      "41                            [Internet of Things]\n",
      "42                                              []\n",
      "43                              [Embedded Systems]\n",
      "44     [Robotics, Blockchain, Commercial Projects]\n",
      "45                           [Computer Networking]\n",
      "46                          [Software Engineering]\n",
      "47                                              []\n",
      "48                              [Embedded Systems]\n",
      "49                                [Antenna Design]\n",
      "50                                              []\n",
      "51                                              []\n",
      "52                                              []\n",
      "Name: standardised Expertise 3, dtype: object\n",
      "\n",
      "DataFrame with standardised Expertise:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Expertise Area 1</th>\n",
       "      <th>Expertise Area 2</th>\n",
       "      <th>Expertise Area 3</th>\n",
       "      <th>standardised Expertise 1</th>\n",
       "      <th>standardised Expertise 2</th>\n",
       "      <th>standardised Expertise 3</th>\n",
       "      <th>standardised Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali Afzalian Mand</td>\n",
       "      <td>[Machine Learning Theory]</td>\n",
       "      <td>[AI for Healthcare]</td>\n",
       "      <td>[Deep Learning, Neural Networks]</td>\n",
       "      <td>[Machine Learning]</td>\n",
       "      <td>[AI for Healthcare]</td>\n",
       "      <td>[Deep Learning, Neural Networks]</td>\n",
       "      <td>Machine Learning, AI for Healthcare, Deep Lear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assoc. Prof. Dr Anwar P.P. Abdul Majeed</td>\n",
       "      <td>[Machine Learning, Deep Learning]</td>\n",
       "      <td>[Data Analytics]</td>\n",
       "      <td>[Robotics]</td>\n",
       "      <td>[Machine Learning, Deep Learning]</td>\n",
       "      <td>[Data Analytics]</td>\n",
       "      <td>[Robotics]</td>\n",
       "      <td>Machine Learning, Deep Learning, Data Analytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assoc. Prof. Dr Azam Che Idris</td>\n",
       "      <td>[DEEP LEARNING, MACHINE LEARNING]</td>\n",
       "      <td>[TIME SERIES ANALYSIS]</td>\n",
       "      <td>[COMPUTER VISION]</td>\n",
       "      <td>[Deep Learning, Machine Learning]</td>\n",
       "      <td>[Time Series Analysis]</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>Deep Learning, Machine Learning, Time Series A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assoc. Prof. Dr Muhammed Basheer Jasser</td>\n",
       "      <td>[Machine Learning, Artificial Intelligence]</td>\n",
       "      <td>[Swarm and Evolutionary Computing]</td>\n",
       "      <td>[Software Engineering, Software Modeling]</td>\n",
       "      <td>[Machine Learning, Artificial Intelligence]</td>\n",
       "      <td>[Swarm and Evolutionary Computing]</td>\n",
       "      <td>[Software Engineering, Software Engineering]</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Swa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc. Prof. Dr Aslina Baharum</td>\n",
       "      <td>[AI-UX, UX/UI Research &amp; Design, HCI, Interact...</td>\n",
       "      <td>[Software Engineering &amp; Development, Informati...</td>\n",
       "      <td>[Information and Communication Technology (ICT...</td>\n",
       "      <td>[UX/UI Design, UX/UI Design, Human-Computer In...</td>\n",
       "      <td>[Software Engineering, Information Visualization]</td>\n",
       "      <td>[Information Technology, Computer Science]</td>\n",
       "      <td>UX/UI Design, Human-Computer Interaction, Inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name  \\\n",
       "0                        Ali Afzalian Mand   \n",
       "1  Assoc. Prof. Dr Anwar P.P. Abdul Majeed   \n",
       "2           Assoc. Prof. Dr Azam Che Idris   \n",
       "3  Assoc. Prof. Dr Muhammed Basheer Jasser   \n",
       "4           Assoc. Prof. Dr Aslina Baharum   \n",
       "\n",
       "                                    Expertise Area 1  \\\n",
       "0                          [Machine Learning Theory]   \n",
       "1                  [Machine Learning, Deep Learning]   \n",
       "2                  [DEEP LEARNING, MACHINE LEARNING]   \n",
       "3        [Machine Learning, Artificial Intelligence]   \n",
       "4  [AI-UX, UX/UI Research & Design, HCI, Interact...   \n",
       "\n",
       "                                    Expertise Area 2  \\\n",
       "0                                [AI for Healthcare]   \n",
       "1                                   [Data Analytics]   \n",
       "2                             [TIME SERIES ANALYSIS]   \n",
       "3                 [Swarm and Evolutionary Computing]   \n",
       "4  [Software Engineering & Development, Informati...   \n",
       "\n",
       "                                    Expertise Area 3  \\\n",
       "0                   [Deep Learning, Neural Networks]   \n",
       "1                                         [Robotics]   \n",
       "2                                  [COMPUTER VISION]   \n",
       "3          [Software Engineering, Software Modeling]   \n",
       "4  [Information and Communication Technology (ICT...   \n",
       "\n",
       "                            standardised Expertise 1  \\\n",
       "0                                 [Machine Learning]   \n",
       "1                  [Machine Learning, Deep Learning]   \n",
       "2                  [Deep Learning, Machine Learning]   \n",
       "3        [Machine Learning, Artificial Intelligence]   \n",
       "4  [UX/UI Design, UX/UI Design, Human-Computer In...   \n",
       "\n",
       "                            standardised Expertise 2  \\\n",
       "0                                [AI for Healthcare]   \n",
       "1                                   [Data Analytics]   \n",
       "2                             [Time Series Analysis]   \n",
       "3                 [Swarm and Evolutionary Computing]   \n",
       "4  [Software Engineering, Information Visualization]   \n",
       "\n",
       "                       standardised Expertise 3  \\\n",
       "0              [Deep Learning, Neural Networks]   \n",
       "1                                    [Robotics]   \n",
       "2                             [Computer Vision]   \n",
       "3  [Software Engineering, Software Engineering]   \n",
       "4    [Information Technology, Computer Science]   \n",
       "\n",
       "                                 standardised Topics  \n",
       "0  Machine Learning, AI for Healthcare, Deep Lear...  \n",
       "1  Machine Learning, Deep Learning, Data Analytic...  \n",
       "2  Deep Learning, Machine Learning, Time Series A...  \n",
       "3  Machine Learning, Artificial Intelligence, Swa...  \n",
       "4  UX/UI Design, Human-Computer Interaction, Inte...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "standardisation map saved to: data\\gemini_standardisation_map.json\n",
      "Augmented DataFrame saved to CSV: data\\supervisors_standardised_gemini.csv\n",
      "\n",
      "Unique individual standardised topic terms found across all supervisors:\n",
      "['AI for Healthcare', 'Antenna Design', 'Application Development', 'Artificial Intelligence', 'Augmented Reality', 'Automated Test and Measurement Systems', 'Blockchain', 'Cloud Computing', 'Clustering Algorithms & Optimization', 'Commercial Projects', 'Computer Engineering', 'Computer Graphics', 'Computer Networking', 'Computer Science', 'Computer Vision', 'Cybersecurity', 'Data Analytics', 'Data Mining', 'Data Science', 'Databases', 'Deep Learning', 'Distributed Haptics', 'Distributed Systems', 'E-commerce games', 'Electronics', 'Embedded Systems', 'Environment', 'Extended Reality', 'Fiber Optic Sensor', 'Generative AI', 'Green Computing', 'Healthcare', 'Human-Computer Interaction', 'Image Processing', 'Information Systems', 'Information Technology', 'Information Visualization', 'Interaction Design', 'Internet of Things', 'Machine Learning', 'Mixed Reality', 'Mobile Development', 'Nanomaterials', 'Natural Language Processing', 'Network Coding', 'Network Security', 'Neural Networks', 'Neuroscience', 'Operational Optimisation', 'Pattern Recognition', 'Photonic Devices', 'Product Design', 'Qualitative Research', 'Renewable Energy System Management', 'Robotics', 'Signal Processing', 'Smart Cities', 'Software Engineering', 'Swarm and Evolutionary Computing', 'Time Series Analysis', 'UX/UI Design', 'Ultrasound Indoor Localization', 'Virtual Reality', 'Wireless Communication']\n",
      "Unique standardised topics saved to: data\\unique_standardised_topics.csv\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "from IPython.display import display, Markdown # For better display in notebooks\n",
    "from ast import literal_eval\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyBr8aF6h4Vp1LpwxbKtD8KvuaCfUcl-2MM'\n",
    "\n",
    "# --- Configuration ---\n",
    "try:\n",
    "    # Attempt to configure from environment variable\n",
    "    if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "        print(\"Warning: GOOGLE_API_KEY environment variable not set.\")\n",
    "    genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring Gemini API: {e}\")\n",
    "    print(\"Please ensure your GOOGLE_API_KEY is correctly set.\")\n",
    "    exit(1)\n",
    "\n",
    "try:\n",
    "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Gemini model: {e}\")\n",
    "    model = None\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def extract_unique_expertise_terms(df, expertise_cols):\n",
    "    \"\"\"Extracts all unique, non-empty expertise terms from specified columns.\"\"\"\n",
    "    all_terms = set()\n",
    "    for col in expertise_cols:\n",
    "        # Ensure column exists and handle potential errors if it doesn't\n",
    "        if col in df.columns:\n",
    "            # Drop NaNs\n",
    "            col_data = df[col].dropna()\n",
    "            for item in col_data:\n",
    "                # If the cell is a list, extend; if string, treat as single topic\n",
    "                if isinstance(item, list):\n",
    "                    all_terms.update([t.strip() for t in item if t and str(t).strip()])\n",
    "                else:\n",
    "                    # Try to parse string representation of list, else treat as single string\n",
    "                    try:\n",
    "                        parsed = eval(item) if isinstance(item, str) and item.startswith(\"[\") else item\n",
    "                        if isinstance(parsed, list):\n",
    "                            all_terms.update([t.strip() for t in parsed if t and str(t).strip()])\n",
    "                        else:\n",
    "                            if str(parsed).strip():\n",
    "                                all_terms.add(str(parsed).strip())\n",
    "                    except Exception:\n",
    "                        if str(item).strip():\n",
    "                            all_terms.add(str(item).strip())\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in DataFrame.\")\n",
    "    return sorted(list(all_terms))\n",
    "\n",
    "def get_standardisation_map_from_gemini(unique_terms_list):\n",
    "    \"\"\"\n",
    "    Sends a list of unique expertise terms to Gemini and asks for a standardisation map.\n",
    "    Returns a dictionary: {\"original_term\": \"standardised_term\"}.\n",
    "    \"\"\"\n",
    "    if not model:\n",
    "        print(\"Gemini model not initialized. Cannot proceed.\")\n",
    "        return None\n",
    "    if not unique_terms_list:\n",
    "        print(\"No unique terms provided to standardise.\")\n",
    "        return {}\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert academic research field categorizer and data normalizer.\n",
    "    I have a list of expertise areas extracted from a dataset of supervisors.\n",
    "    Many of these terms are variations of the same concept (e.g., \"IoT\", \"Internet of Things\", \"Industrial IoT\")\n",
    "    or very closely related.\n",
    "\n",
    "    Your task is to analyze the following list of unique expertise terms and create a JSON object\n",
    "    that maps each original term to a single, consistent, standardised \"umbrella\" term.\n",
    "    Your aim is to reduce redundancy and ensure that similar or synonymous terms are grouped under \n",
    "    a single standardised term to be used for labeling and categorization of student's preferences in a university database.\n",
    "\n",
    "    Guidelines:\n",
    "    1. The standardised term should be a concise and commonly understood representation of the concept.\n",
    "    2. If an original term is already a good standard, it can map to itself.\n",
    "    3. Group synonymous or similar terms under ONE standardised term. For example, if \"Machine Learning\", \"ML\", and \"Deep Learning\" are present, they might all map to \"Machine Learning\" or you might decide \"Deep Learning\" should map to \"Deep Learning\" if it's distinct enough, while \"ML\" maps to \"Machine Learning\". Use your best judgment to create meaningful umbrella terms.\n",
    "    4. The output MUST be a single JSON object where keys are the *original* expertise terms from the input list, and values are their corresponding *standardised* umbrella terms. Every term from the input list must be a key in the output JSON.\n",
    "    5. Do not include any explanatory text outside the JSON object. Just the JSON.\n",
    "\n",
    "    List of unique expertise terms:\n",
    "    {json.dumps(unique_terms_list)}\n",
    "\n",
    "    Please provide the JSON mapping:\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Sending request to Gemini API...\")\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        # Gemini API can sometimes wrap JSON in markdown backticks\n",
    "        cleaned_response_text = response.text.strip().removeprefix(\"```json\").removeprefix(\"```\").removesuffix(\"```\").strip()\n",
    "\n",
    "        # Validate and parse JSON\n",
    "        try:\n",
    "            standardisation_map = json.loads(cleaned_response_text)\n",
    "            # Basic validation: ensure it's a dict\n",
    "            if not isinstance(standardisation_map, dict):\n",
    "                print(\"Error: Gemini did not return a valid JSON dictionary.\")\n",
    "                print(\"Raw response:\", response.text)\n",
    "                return None\n",
    "            # Ensure all original terms are keys\n",
    "            missing_keys = [term for term in unique_terms_list if term not in standardisation_map]\n",
    "            if missing_keys:\n",
    "                print(f\"Warning: Gemini's map is missing keys for: {missing_keys}\")\n",
    "                for key in missing_keys:\n",
    "                    standardisation_map[key] = key # self-mapping\n",
    "            return standardisation_map\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from Gemini: {e}\")\n",
    "            print(\"Raw response text from Gemini:\")\n",
    "            print(response.text) # print the raw response for debugging\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Gemini API: {e}\")\n",
    "        if hasattr(e, 'response') and e.response: # More detailed error if available\n",
    "            print(f\"Gemini API Error Details: {e.response}\")\n",
    "        return None\n",
    "\n",
    "# --- Main Processing ---\n",
    "\n",
    "# 1. Load CSV\n",
    "csv_file_path = 'data\\\\supervisors_list.csv' # <--- CHANGE FILENAME\n",
    "expertise_columns = ['Expertise Area 1', 'Expertise Area 2', 'Expertise Area 3']\n",
    "\n",
    "try:\n",
    "    supervisors_df = pd.read_csv(csv_file_path)\n",
    "    for col in expertise_columns:\n",
    "        if col not in supervisors_df.columns:\n",
    "            print(f\"Warning: Column '{col}' not found in CSV. Skipping standardisation for this column.\")\n",
    "            expertise_columns.remove(col)\n",
    "        else:\n",
    "            # Ensure expertise columns are treated as lists\n",
    "            supervisors_df[col] = supervisors_df[col].apply(literal_eval)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{csv_file_path}' not found. Using dummy data for demonstration.\")\n",
    "    data = {\n",
    "        'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "        'Department': ['CS', 'CS', 'AI', 'CS', 'EE'],\n",
    "        'Preferred Programme for Supervision (1st Choice)': ['PhD CS', 'MSc AI', 'PhD AI', 'MSc DS', 'PhD EE'],\n",
    "        'Preferred Programme for Supervision (2nd Choice)': ['MSc AI', 'PhD CS', 'MSc DS', 'PhD CS', 'MSc CS'],\n",
    "        'Expertise Area 1': ['Machine Learning', 'Software Architecture', 'Natural Language Processing', 'Data Mining', 'IoT'],\n",
    "        'Expertise Area 2': ['Deep Learning', 'Agile Development', pd.NA, 'Big Data Analytics', 'Internet of Things'],\n",
    "        'Expertise Area 3': ['Computer Vision', pd.NA, 'Ethics in AI', 'Cloud Computing', 'Industrial IoT']\n",
    "    }\n",
    "    supervisors_df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame sample:\")\n",
    "display(supervisors_df.head())\n",
    "\n",
    "# 2. Extract All Unique Expertise Terms\n",
    "unique_terms = extract_unique_expertise_terms(supervisors_df, expertise_columns)\n",
    "if not unique_terms:\n",
    "    print(\"No expertise terms found to process. Exiting.\")\n",
    "    exit()\n",
    "else:\n",
    "    print(f\"\\nFound {len(unique_terms)} unique expertise terms to standardise:\")\n",
    "    print(unique_terms)\n",
    "\n",
    "    # 3. Get standardisation Map from Gemini (only if model initialized and terms exist)\n",
    "    standardisation_dictionary = None\n",
    "    if model and unique_terms:\n",
    "        standardisation_dictionary = get_standardisation_map_from_gemini(unique_terms)\n",
    "\n",
    "    if standardisation_dictionary:\n",
    "        print(\"\\n--- standardisation Map from Gemini (Review this carefully!) ---\")\n",
    "        # Pretty print the dictionary for review\n",
    "        display(Markdown(\"```json\\n\" + json.dumps(standardisation_dictionary, indent=2) + \"\\n```\"))\n",
    "\n",
    "        # --- Maybe include manual review here? ---\n",
    "\n",
    "        # 4. Apply Mapping to Create standardised Expertise Columns\n",
    "        print(\"\\nApplying standardisation map to DataFrame...\")\n",
    "        for i, col_name in enumerate(expertise_columns):\n",
    "            if col_name in supervisors_df.columns:\n",
    "                standardised_col_name = f'standardised Expertise {i+1}'\n",
    "                supervisors_df[standardised_col_name] = supervisors_df[col_name].apply(\n",
    "                    lambda topics: [standardisation_dictionary.get(t.strip(), t.strip()) for t in topics] if isinstance(topics, list)\n",
    "                    else [standardisation_dictionary.get(str(topics), str(topics))] if pd.notna(topics) and str(topics).strip()\n",
    "                    else []\n",
    "                )\n",
    "                print(supervisors_df[standardised_col_name])\n",
    "            else:\n",
    "                print(f\"Skipping standardisation for non-existent column: {col_name}\")\n",
    "\n",
    "\n",
    "        # 5. Combine standardised Expertise into a single columnI\n",
    "        standardised_expertise_cols = [f'standardised Expertise {i+1}' for i in range(len(expertise_columns)) if f'standardised Expertise {i+1}' in supervisors_df.columns]\n",
    "\n",
    "        if standardised_expertise_cols: # only proceed if standardised columns were created\n",
    "            supervisors_df['standardised Topics'] = supervisors_df.apply(\n",
    "                lambda x: combine_expertise_topics(x, standardised_expertise_cols),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            print(\"\\nDataFrame with standardised Expertise:\")\n",
    "            display(supervisors_df[['Name'] + expertise_columns + standardised_expertise_cols + ['standardised Topics']].head())\n",
    "\n",
    "            # 6. Save Outputs\n",
    "            # Save the standardisation map to a JSON file\n",
    "            map_output_path = 'data\\\\gemini_standardisation_map.json'\n",
    "            with open(map_output_path, 'w') as f:\n",
    "                json.dump(standardisation_dictionary, f, indent=4)\n",
    "            print(f\"\\nstandardisation map saved to: {map_output_path}\")\n",
    "\n",
    "            # Save the augmented DataFrame to CSV\n",
    "            csv_output_path = 'data\\\\supervisors_standardised_gemini.csv'\n",
    "            supervisors_df.to_csv(csv_output_path, index=False)\n",
    "            print(f\"Augmented DataFrame saved to CSV: {csv_output_path}\")\n",
    "\n",
    "            # Example: Further manipulation - unique standardised topics\n",
    "            if 'standardised Topics' in supervisors_df.columns:\n",
    "                unique_standardised_topics_list = supervisors_df['standardised Topics'].str.split(', ').explode().str.strip()\n",
    "                unique_standardised_topics_list = unique_standardised_topics_list[unique_standardised_topics_list != ''].unique()\n",
    "                print(\"\\nUnique individual standardised topic terms found across all supervisors:\")\n",
    "                print(sorted(list(unique_standardised_topics_list)))\n",
    "\n",
    "                # Save unique standardised topics to CSV\n",
    "                unique_topics_df = pd.DataFrame({'standardised Topic': sorted(list(unique_standardised_topics_list))})\n",
    "                unique_topics_df.to_csv('data\\\\unique_standardised_topics.csv', index=False)\n",
    "                print(\"Unique standardised topics saved to: data\\\\unique_standardised_topics.csv\")\n",
    "        else:\n",
    "            print(\"\\nNo standardised expertise columns were created. Skipping combination and saving of DataFrame.\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nFailed to get standardisation map from Gemini. No changes applied to DataFrame.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f01545",
   "metadata": {},
   "source": [
    "## Test labeling accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "625589d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 64 standardized topics: ['AI for Healthcare', 'Antenna Design', 'Application Development', 'Artificial Intelligence', 'Augmented Reality']...\n",
      "Processing in 4 batches of size up to 50.\n",
      "\n",
      "--- Processing Batch 1/4 (50 sentences) ---\n",
      "Attempt 1/3 for batch 1...\n",
      "Successfully processed batch 1. Received 50 results.\n",
      "Waiting 2s before next batch...\n",
      "\n",
      "--- Processing Batch 2/4 (50 sentences) ---\n",
      "Attempt 1/3 for batch 2...\n",
      "Successfully processed batch 2. Received 50 results.\n",
      "Waiting 2s before next batch...\n",
      "\n",
      "--- Processing Batch 3/4 (50 sentences) ---\n",
      "Attempt 1/3 for batch 3...\n",
      "Successfully processed batch 3. Received 50 results.\n",
      "Waiting 2s before next batch...\n",
      "\n",
      "--- Processing Batch 4/4 (30 sentences) ---\n",
      "Attempt 1/3 for batch 4...\n",
      "Successfully processed batch 4. Received 30 results.\n",
      "\n",
      "Successfully parsed all Gemini batch outputs. Total results: 180\n",
      "  SentenceID                             Gemini_Positive_Topics  \\\n",
      "0          1         [Artificial Intelligence, Neural Networks]   \n",
      "1          2  [Virtual Reality, Augmented Reality, Extended ...   \n",
      "2          3                     [Green Computing, Environment]   \n",
      "3          4                 [Mobile Development, UX/UI Design]   \n",
      "4          5  [Computer Vision, Image Processing, Artificial...   \n",
      "\n",
      "                              Gemini_Negative_Topics  \n",
      "0         [Distributed Systems, Computer Networking]  \n",
      "1             [Fiber Optic Sensor, Photonic Devices]  \n",
      "2  [Blockchain, Cybersecurity, Information Security]  \n",
      "3             [Data Analytics, Time Series Analysis]  \n",
      "4             [Embedded Systems, Internet of Things]  \n",
      "\n",
      "--- Classification Report for POSITIVE Topics ---\n",
      "Debug: Number of active positive class indices: 52\n",
      "Debug: Number of active positive target names: 52\n",
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "                     AI for Healthcare       0.00      0.00      0.00         0\n",
      "               Application Development       0.00      0.00      0.00         0\n",
      "               Artificial Intelligence       0.36      1.00      0.53         4\n",
      "                     Augmented Reality       1.00      1.00      1.00         4\n",
      "Automated Test and Measurement Systems       0.80      1.00      0.89         4\n",
      "                            Blockchain       1.00      1.00      1.00         3\n",
      "                       Cloud Computing       1.00      1.00      1.00         4\n",
      "                   Commercial Projects       1.00      1.00      1.00         1\n",
      "                  Computer Engineering       0.00      0.00      0.00         0\n",
      "                     Computer Graphics       1.00      1.00      1.00         1\n",
      "                   Computer Networking       0.00      0.00      0.00         0\n",
      "                      Computer Science       0.00      0.00      0.00         0\n",
      "                       Computer Vision       1.00      1.00      1.00         4\n",
      "                         Cybersecurity       0.75      1.00      0.86         3\n",
      "                        Data Analytics       0.29      1.00      0.44         4\n",
      "                           Data Mining       0.50      1.00      0.67         2\n",
      "                          Data Science       0.00      0.00      0.00         0\n",
      "                             Databases       1.00      1.00      1.00         4\n",
      "                         Deep Learning       1.00      0.75      0.86         4\n",
      "                   Distributed Systems       0.75      1.00      0.86         3\n",
      "                      E-commerce games       0.00      0.00      0.00         1\n",
      "                      Embedded Systems       1.00      1.00      1.00         1\n",
      "                           Environment       0.00      0.00      0.00         0\n",
      "                      Extended Reality       1.00      1.00      1.00         3\n",
      "                         Generative AI       0.60      1.00      0.75         3\n",
      "                       Green Computing       1.00      1.00      1.00         3\n",
      "                            Healthcare       0.30      1.00      0.46         3\n",
      "            Human-Computer Interaction       0.43      1.00      0.60         3\n",
      "                      Image Processing       0.80      1.00      0.89         4\n",
      "                   Information Systems       0.25      1.00      0.40         1\n",
      "             Information Visualization       1.00      1.00      1.00         4\n",
      "                    Interaction Design       1.00      0.67      0.80         3\n",
      "                    Internet of Things       0.67      1.00      0.80         4\n",
      "                      Machine Learning       0.57      1.00      0.73         4\n",
      "                         Mixed Reality       0.00      0.00      0.00         1\n",
      "                    Mobile Development       0.00      0.00      0.00         0\n",
      "           Natural Language Processing       1.00      1.00      1.00         5\n",
      "                        Network Coding       1.00      1.00      1.00         1\n",
      "                      Network Security       1.00      1.00      1.00         4\n",
      "                       Neural Networks       0.83      1.00      0.91         5\n",
      "              Operational Optimisation       0.00      0.00      0.00         0\n",
      "                   Pattern Recognition       0.75      1.00      0.86         3\n",
      "                        Product Design       0.50      1.00      0.67         1\n",
      "                              Robotics       0.60      1.00      0.75         3\n",
      "                     Signal Processing       0.00      0.00      0.00         0\n",
      "                          Smart Cities       0.00      0.00      0.00         0\n",
      "                  Software Engineering       0.44      1.00      0.62         4\n",
      "      Swarm and Evolutionary Computing       0.00      0.00      0.00         0\n",
      "                  Time Series Analysis       1.00      1.00      1.00         1\n",
      "                          UX/UI Design       0.00      0.00      0.00         0\n",
      "                       Virtual Reality       0.67      1.00      0.80         4\n",
      "                Wireless Communication       0.00      0.00      0.00         0\n",
      "\n",
      "                             micro avg       0.38      0.96      0.54       114\n",
      "                             macro avg       0.54      0.68      0.58       114\n",
      "                          weighted avg       0.76      0.96      0.82       114\n",
      "                           samples avg       0.30      0.39      0.33       114\n",
      "\n",
      "\n",
      "--- Classification Report for NEGATIVE Topics ---\n",
      "Debug: Number of active negative class indices: 59\n",
      "Debug: Number of active negative target names: 59\n",
      "                                        precision    recall  f1-score   support\n",
      "\n",
      "                     AI for Healthcare       0.00      0.00      0.00         0\n",
      "                        Antenna Design       1.00      1.00      1.00         3\n",
      "               Application Development       0.00      0.00      0.00         0\n",
      "               Artificial Intelligence       1.00      1.00      1.00         1\n",
      "                     Augmented Reality       1.00      1.00      1.00         1\n",
      "Automated Test and Measurement Systems       1.00      1.00      1.00         1\n",
      "                            Blockchain       1.00      1.00      1.00         2\n",
      "                       Cloud Computing       1.00      1.00      1.00         2\n",
      "  Clustering Algorithms & Optimization       1.00      1.00      1.00         2\n",
      "                   Commercial Projects       0.25      1.00      0.40         1\n",
      "                  Computer Engineering       0.75      1.00      0.86         3\n",
      "                     Computer Graphics       0.67      1.00      0.80         2\n",
      "                   Computer Networking       0.20      1.00      0.33         1\n",
      "                       Computer Vision       1.00      1.00      1.00         1\n",
      "                         Cybersecurity       0.67      1.00      0.80         2\n",
      "                        Data Analytics       0.17      1.00      0.29         1\n",
      "                          Data Science       0.00      0.00      0.00         0\n",
      "                         Deep Learning       1.00      1.00      1.00         1\n",
      "                   Distributed Haptics       0.00      0.00      0.00         0\n",
      "                   Distributed Systems       0.50      1.00      0.67         2\n",
      "                      E-commerce games       0.57      1.00      0.73         4\n",
      "                           Electronics       1.00      1.00      1.00         4\n",
      "                      Embedded Systems       0.67      1.00      0.80         2\n",
      "                           Environment       0.50      1.00      0.67         3\n",
      "                      Extended Reality       1.00      1.00      1.00         1\n",
      "                    Fiber Optic Sensor       1.00      1.00      1.00         3\n",
      "                         Generative AI       1.00      1.00      1.00         1\n",
      "                       Green Computing       0.25      1.00      0.40         1\n",
      "                            Healthcare       0.12      1.00      0.22         1\n",
      "            Human-Computer Interaction       1.00      1.00      1.00         1\n",
      "                      Image Processing       0.33      1.00      0.50         1\n",
      "                   Information Systems       1.00      1.00      1.00         1\n",
      "                Information Technology       1.00      1.00      1.00         3\n",
      "             Information Visualization       1.00      1.00      1.00         1\n",
      "                    Interaction Design       1.00      1.00      1.00         1\n",
      "                    Internet of Things       0.50      1.00      0.67         1\n",
      "                      Machine Learning       0.50      1.00      0.67         1\n",
      "                         Mixed Reality       1.00      1.00      1.00         3\n",
      "                    Mobile Development       0.00      0.00      0.00         0\n",
      "                         Nanomaterials       1.00      1.00      1.00         3\n",
      "                        Network Coding       1.00      1.00      1.00         3\n",
      "                      Network Security       1.00      1.00      1.00         1\n",
      "                       Neural Networks       1.00      1.00      1.00         1\n",
      "                          Neuroscience       1.00      1.00      1.00         3\n",
      "                   Pattern Recognition       1.00      1.00      1.00         1\n",
      "                      Photonic Devices       1.00      1.00      1.00         3\n",
      "                        Product Design       1.00      1.00      1.00         2\n",
      "                  Qualitative Research       1.00      1.00      1.00         3\n",
      "    Renewable Energy System Management       0.00      0.00      0.00         0\n",
      "                              Robotics       1.00      1.00      1.00         2\n",
      "                     Signal Processing       1.00      1.00      1.00         3\n",
      "                          Smart Cities       0.00      0.00      0.00         0\n",
      "                  Software Engineering       0.00      0.00      0.00         1\n",
      "      Swarm and Evolutionary Computing       0.00      0.00      0.00         0\n",
      "                  Time Series Analysis       1.00      1.00      1.00         2\n",
      "                          UX/UI Design       0.00      0.00      0.00         0\n",
      "        Ultrasound Indoor Localization       0.00      0.00      0.00         0\n",
      "                       Virtual Reality       1.00      1.00      1.00         1\n",
      "                Wireless Communication       0.60      1.00      0.75         3\n",
      "\n",
      "                             micro avg       0.47      0.99      0.64        91\n",
      "                             macro avg       0.67      0.81      0.70        91\n",
      "                          weighted avg       0.84      0.99      0.88        91\n",
      "                           samples avg       0.31      0.39      0.34        91\n",
      "\n",
      "\n",
      "Successfully saved Gemini's labels and comparison to 'data\\gemini_labeled_preferences.csv'\n",
      "\n",
      "--- Script Finished ---\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "\n",
    "# --- Configuration ---\n",
    "GEMINI_MODEL_NAME = \"gemini-2.0-flash\"\n",
    "STUDENT_PREFERENCES_CSV = \"data\\\\claude_sentences.csv\"\n",
    "STANDARDIZED_TOPICS_CSV = \"data\\\\unique_standardised_topics.csv\"\n",
    "OUTPUT_CSV_WITH_GEMINI_LABELS = \"data\\\\gemini_labeled_preferences.csv\"\n",
    "API_RETRY_LIMIT = 3\n",
    "API_RETRY_DELAY_SECONDS = 5\n",
    "BATCH_SIZE = 50\n",
    "DELAY_BETWEEN_BATCHES_SECONDS = 2\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyBr8aF6h4Vp1LpwxbKtD8KvuaCfUcl-2MM'\n",
    "\n",
    "# --- 1. Configure Gemini API ---\n",
    "try:\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"GOOGLE_API_KEY environment variable not set.\")\n",
    "    genai.configure(api_key=api_key)\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring Gemini API: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Load Data ---\n",
    "try:\n",
    "    student_df_full = pd.read_csv(STUDENT_PREFERENCES_CSV)\n",
    "    topics_df = pd.read_csv(STANDARDIZED_TOPICS_CSV)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Make sure your CSV files are in the correct path.\")\n",
    "    exit()\n",
    "except pd.errors.EmptyDataError as e:\n",
    "    print(f\"Error: {e}. One of your CSV files might be empty.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Ensure expected columns exist in student_df\n",
    "required_cols = ['Entry', 'Positive_Topics', 'Negative_Topics']\n",
    "if not all(col in student_df_full.columns for col in required_cols):\n",
    "    print(f\"Error: {STUDENT_PREFERENCES_CSV} must contain columns: {', '.join(required_cols)}\")\n",
    "    exit()\n",
    "\n",
    "student_df_full.rename(columns={\n",
    "    'Entry': 'SentenceText',\n",
    "    'Positive_Topics': 'Human_Positive_Topics',\n",
    "    'Negative_Topics': 'Human_Negative_Topics'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add sentence ID if not present\n",
    "if 'SentenceID' not in student_df_full.columns:\n",
    "    student_df_full['SentenceID'] = student_df_full.index + 1  # Create a simple ID based on index\n",
    "\n",
    "# Get the list of standardized topics\n",
    "if topics_df.empty or topics_df.columns.empty:\n",
    "    print(f\"Error: {STANDARDIZED_TOPICS_CSV} is empty or has no columns. It should have one column with topics.\")\n",
    "    exit()\n",
    "standardized_topic_list = topics_df.iloc[:, 0].astype(str).str.strip().unique().tolist()\n",
    "print(f\"Loaded {len(standardized_topic_list)} standardized topics: {standardized_topic_list[:5]}...\") # Print first 5\n",
    "\n",
    "# --- 3. Helper function to create prompt for a batch ---\n",
    "def create_prompt_for_batch(batch_sentences_list, all_standardized_topics):\n",
    "    sentences_json_for_prompt = json.dumps(batch_sentences_list, indent=2)\n",
    "    prompt = f\"\"\"\n",
    "You are an expert AI assistant specialized in classifying student project preferences.\n",
    "Your task is to label a list of student preference sentences with relevant project topics, both positive and negative.\n",
    "You MUST use ONLY the topics from the provided standardized list.\n",
    "\n",
    "Standardized Topics List:\n",
    "{', '.join(all_standardized_topics)}\n",
    "\n",
    "Input Sentences for this batch (as a JSON array of objects):\n",
    "{sentences_json_for_prompt}\n",
    "\n",
    "Instructions:\n",
    "1.  For each sentence object in the input JSON array, analyze the \"SentenceText\".\n",
    "2.  Identify topics the student expresses a POSITIVE preference for.\n",
    "3.  Identify topics the student expresses a NEGATIVE preference for.\n",
    "4.  Topics MUST be chosen EXACTLY from the 'Standardized Topics List' above. Do not invent new topics or use variations. IF there is NO MATCH, label it as 'No Match'.\n",
    "5.  Your output MUST be a valid JSON array of objects.\n",
    "6.  Each object in your output array should correspond to an input sentence and have the following keys:\n",
    "    *   \"SentenceID\": (string) The ID from the input sentence object.\n",
    "    *   \"Gemini_Positive_Topics\": (array of strings) A list of positive topics. If no positive topics, label it as 'No Match'.\n",
    "    *   \"Gemini_Negative_Topics\": (array of strings) A list of negative topics. If no negative topics, label it as 'No Match'.\n",
    "7.  Ensure every SentenceID from the input batch is present in your output JSON array.\n",
    "8.  Do NOT include the original 'SentenceText' in your output JSON, only the specified keys.\n",
    "\n",
    "Example of expected output JSON format:\n",
    "[\n",
    "  {{\n",
    "    \"SentenceID\": \"S001\",\n",
    "    \"Gemini_Positive_Topics\": [\"Machine Learning\", \"Artificial Intelligence\"],\n",
    "    \"Gemini_Negative_Topics\": [\"Web Development\"]\n",
    "  }},\n",
    "  {{\n",
    "    \"SentenceID\": \"S002\",\n",
    "    \"Gemini_Positive_Topics\": [\"Data Science\"],\n",
    "    \"Gemini_Negative_Topics\": []\n",
    "  }}\n",
    "]\n",
    "\n",
    "Begin your JSON output now (ensure it's a single, valid JSON array for this batch):\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# --- 4. Process Sentences in Batches ---\n",
    "model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "all_gemini_results = [] # To store results from all batches\n",
    "\n",
    "num_batches = math.ceil(len(student_df_full) / BATCH_SIZE)\n",
    "print(f\"Processing in {num_batches} batches of size up to {BATCH_SIZE}.\")\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start_index = i * BATCH_SIZE\n",
    "    end_index = start_index + BATCH_SIZE\n",
    "    batch_df = student_df_full.iloc[start_index:end_index]\n",
    "\n",
    "    print(f\"\\n--- Processing Batch {i+1}/{num_batches} ({len(batch_df)} sentences) ---\")\n",
    "\n",
    "    if batch_df.empty:\n",
    "        print(\"Batch is empty, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Prepare list of sentences for the current batch's prompt\n",
    "    batch_sentences_to_label_list = []\n",
    "    for _, row in batch_df.iterrows():\n",
    "        batch_sentences_to_label_list.append({\n",
    "            \"SentenceID\": str(row['SentenceID']),\n",
    "            \"SentenceText\": row['SentenceText']\n",
    "        })\n",
    "\n",
    "    batch_prompt = create_prompt_for_batch(batch_sentences_to_label_list, standardized_topic_list)\n",
    "\n",
    "    gemini_output_json_str = None\n",
    "    current_batch_results = None\n",
    "\n",
    "    for attempt in range(API_RETRY_LIMIT):\n",
    "        try:\n",
    "            print(f\"Attempt {attempt + 1}/{API_RETRY_LIMIT} for batch {i+1}...\")\n",
    "            response = model.generate_content(\n",
    "                batch_prompt,\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    # temperature=0.1\n",
    "                )\n",
    "            )\n",
    "            if not response.parts:\n",
    "                if response.prompt_feedback and response.prompt_feedback.block_reason:\n",
    "                    print(f\"Warning: Prompt for batch {i+1} was blocked. Reason: {response.prompt_feedback.block_reason}\")\n",
    "                else:\n",
    "                    print(f\"Warning: Gemini response for batch {i+1} has no parts.\")\n",
    "                if attempt < API_RETRY_LIMIT - 1:\n",
    "                    print(f\"Retrying batch {i+1} in {API_RETRY_DELAY_SECONDS} seconds...\")\n",
    "                    time.sleep(API_RETRY_DELAY_SECONDS)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Max retries reached for problematic response for batch {i+1}. Skipping this batch.\")\n",
    "                    break # Break from retry loop for this batch\n",
    "\n",
    "            gemini_output_json_str = response.text.strip()\n",
    "\n",
    "            if gemini_output_json_str.startswith(\"```json\"):\n",
    "                gemini_output_json_str = gemini_output_json_str[len(\"```json\"):].strip()\n",
    "            if gemini_output_json_str.endswith(\"```\"):\n",
    "                gemini_output_json_str = gemini_output_json_str[:-len(\"```\")].strip()\n",
    "\n",
    "            first_char = gemini_output_json_str[0] if gemini_output_json_str else ''\n",
    "            last_char = gemini_output_json_str[-1] if gemini_output_json_str else ''\n",
    "            if not ((first_char == '[' and last_char == ']')):\n",
    "                json_start_index = gemini_output_json_str.find('[')\n",
    "                json_end_index = gemini_output_json_str.rfind(']')\n",
    "                if json_start_index != -1 and json_end_index > json_start_index :\n",
    "                    gemini_output_json_str = gemini_output_json_str[json_start_index : json_end_index+1]\n",
    "                else:\n",
    "                    raise ValueError(\"Could not reliably extract JSON array from Gemini response for this batch.\")\n",
    "\n",
    "            current_batch_results = json.loads(gemini_output_json_str)\n",
    "            if not isinstance(current_batch_results, list):\n",
    "                raise ValueError(\"Gemini's output for batch was not a JSON list as expected.\")\n",
    "            \n",
    "            print(f\"Successfully processed batch {i+1}. Received {len(current_batch_results)} results.\")\n",
    "            all_gemini_results.extend(current_batch_results)\n",
    "            break # Successful processing of this batch\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error parsing Gemini's JSON output for batch {i+1} (attempt {attempt+1}): {e}\")\n",
    "            print(\"Raw output snippet:\", gemini_output_json_str[:200] if gemini_output_json_str else \"None\")\n",
    "            if attempt < API_RETRY_LIMIT - 1:\n",
    "                time.sleep(API_RETRY_DELAY_SECONDS)\n",
    "            else:\n",
    "                print(f\"Failed to parse JSON for batch {i+1} after {API_RETRY_LIMIT} attempts. Skipping this batch.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during Gemini API call or processing for batch {i+1} (attempt {attempt+1}): {e}\")\n",
    "            if hasattr(response, 'prompt_feedback') and response.prompt_feedback:\n",
    "                 print(f\"Prompt Feedback: {response.prompt_feedback}\")\n",
    "            if attempt < API_RETRY_LIMIT - 1:\n",
    "                time.sleep(API_RETRY_DELAY_SECONDS)\n",
    "            else:\n",
    "                print(f\"Failed to process batch {i+1} after {API_RETRY_LIMIT} attempts. Skipping this batch.\")\n",
    "    \n",
    "    # Optional: Add a small delay between batch calls to be polite to the API\n",
    "    if i < num_batches - 1: # Don't sleep after the last batch\n",
    "        print(f\"Waiting {DELAY_BETWEEN_BATCHES_SECONDS}s before next batch...\")\n",
    "        time.sleep(DELAY_BETWEEN_BATCHES_SECONDS)\n",
    "\n",
    "\n",
    "if not all_gemini_results:\n",
    "    print(\"\\nNo results were successfully processed from Gemini. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# --- 5. Convert All Gemini Results to DataFrame ---\n",
    "gemini_df = pd.DataFrame(all_gemini_results)\n",
    "if gemini_df.empty:\n",
    "    print(\"\\nGemini DataFrame is empty after processing all batches. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "expected_gemini_cols = [\"SentenceID\", \"Gemini_Positive_Topics\", \"Gemini_Negative_Topics\"]\n",
    "if not all(col in gemini_df.columns for col in expected_gemini_cols):\n",
    "    missing_cols = [col for col in expected_gemini_cols if col not in gemini_df.columns]\n",
    "    print(f\"Warning: Gemini's combined JSON output is missing columns: {', '.join(missing_cols)}. Will try to proceed.\")\n",
    "    # Fill missing columns with empty lists if they are essential for later steps\n",
    "    for mc in missing_cols:\n",
    "        if mc not in gemini_df.columns: # Check again, just in case\n",
    "             gemini_df[mc] = [[] for _ in range(len(gemini_df))]\n",
    "\n",
    "\n",
    "print(f\"\\nSuccessfully parsed all Gemini batch outputs. Total results: {len(gemini_df)}\")\n",
    "print(gemini_df.head())\n",
    "\n",
    "\n",
    "# --- 6. Merge Gemini Labels with Ground Truth ---\n",
    "student_df_full['SentenceID'] = student_df_full['SentenceID'].astype(str)\n",
    "gemini_df['SentenceID'] = gemini_df['SentenceID'].astype(str)\n",
    "\n",
    "if gemini_df['SentenceID'].duplicated().any():\n",
    "    print(\"Warning: Gemini's combined output contains duplicate SentenceIDs. Keeping first occurrence.\")\n",
    "    gemini_df = gemini_df.drop_duplicates(subset=['SentenceID'], keep='first')\n",
    "\n",
    "merged_df = pd.merge(student_df_full, gemini_df, on=\"SentenceID\", how=\"left\")\n",
    "\n",
    "for col in ['Gemini_Positive_Topics', 'Gemini_Negative_Topics']:\n",
    "    merged_df[col] = merged_df[col].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# --- 7. Prepare for Classification Report ---\n",
    "def preprocess_topics_from_list(topic_list_series, all_known_topics):\n",
    "    processed_output = []\n",
    "    for topic_list in topic_list_series:\n",
    "        if isinstance(topic_list, list):\n",
    "            valid_topics = [\n",
    "                str(t).strip() for t in topic_list\n",
    "                if isinstance(t, str) and str(t).strip() in all_known_topics\n",
    "            ]\n",
    "            processed_output.append(valid_topics)\n",
    "        else:\n",
    "            processed_output.append([])\n",
    "    return processed_output\n",
    "\n",
    "def human_str_to_list(topic_series, all_known_topics):\n",
    "    processed_list = []\n",
    "    for item in topic_series.fillna(\"\"):\n",
    "        # If already a list, use it directly\n",
    "        if isinstance(item, list):\n",
    "            topics = [str(t).strip() for t in item if str(t).strip()]\n",
    "        # If it's a string representation of a list, safely parse it\n",
    "        elif isinstance(item, str) and item.strip().startswith(\"[\") and item.strip().endswith(\"]\"):\n",
    "            try:\n",
    "                parsed = eval(item)\n",
    "                if isinstance(parsed, list):\n",
    "                    topics = [str(t).strip() for t in parsed if str(t).strip()]\n",
    "                else:\n",
    "                    topics = [str(parsed).strip()] if str(parsed).strip() else []\n",
    "            except Exception:\n",
    "                topics = [item.strip()] if item.strip() else []\n",
    "        elif pd.isna(item) or str(item).lower() == \"none\" or str(item).strip() == \"\":\n",
    "            topics = []\n",
    "        else:\n",
    "            topics = [t.strip() for t in str(item).split(';') if t.strip()]\n",
    "        valid_topics = [t for t in topics if t in all_known_topics]\n",
    "        processed_list.append(valid_topics)\n",
    "    return processed_list\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=standardized_topic_list)\n",
    "\n",
    "human_pos_topics_list = human_str_to_list(merged_df['Human_Positive_Topics'], standardized_topic_list)\n",
    "human_neg_topics_list = human_str_to_list(merged_df['Human_Negative_Topics'], standardized_topic_list)\n",
    "y_human_pos = mlb.fit_transform(human_pos_topics_list)\n",
    "y_human_neg = mlb.transform(human_neg_topics_list)\n",
    "\n",
    "gemini_pos_topics_list = preprocess_topics_from_list(merged_df['Gemini_Positive_Topics'], standardized_topic_list)\n",
    "gemini_neg_topics_list = preprocess_topics_from_list(merged_df['Gemini_Negative_Topics'], standardized_topic_list)\n",
    "y_gemini_pos = mlb.transform(gemini_pos_topics_list)\n",
    "y_gemini_neg = mlb.transform(gemini_neg_topics_list)\n",
    "\n",
    "# --- 8. Generate Classification Reports ---\n",
    "print(\"\\n--- Classification Report for POSITIVE Topics ---\")\n",
    "\n",
    "# y_human_pos and y_gemini_pos have shape (n_samples, n_all_standardized_topics)\n",
    "# mlb.classes_ is the list of all standardized topics (length n_all_standardized_topics)\n",
    "\n",
    "# Determine which classes (column indices) are active (have at least one true or predicted label)\n",
    "active_pos_class_indices = [\n",
    "    i for i, active in enumerate((y_human_pos.sum(axis=0) + y_gemini_pos.sum(axis=0)) > 0) if active\n",
    "]\n",
    "\n",
    "if not active_pos_class_indices:\n",
    "    print(\"No positive topics found in either human or Gemini labels. Skipping positive report or reporting on all.\")\n",
    "    active_pos_class_indices = list(range(len(mlb.classes_))) # All indices from 0 to N-1\n",
    "    if not active_pos_class_indices: # If mlb.classes_ was also empty (edge case)\n",
    "         report_pos_str = \"No topics defined in MLB, cannot generate report.\"\n",
    "         print(report_pos_str)\n",
    "    else:\n",
    "        active_pos_target_names = mlb.classes_\n",
    "        report_pos_str = classification_report(\n",
    "            y_human_pos,\n",
    "            y_gemini_pos,\n",
    "            labels=active_pos_class_indices, \n",
    "            target_names=active_pos_target_names,\n",
    "            zero_division=0,\n",
    "            output_dict=False\n",
    "        )\n",
    "        print(report_pos_str)\n",
    "else:\n",
    "    # Get the names for these active classes from the original mlb.classes_\n",
    "    active_pos_target_names = [mlb.classes_[i] for i in active_pos_class_indices]\n",
    "\n",
    "    print(f\"Debug: Number of active positive class indices: {len(active_pos_class_indices)}\")\n",
    "    print(f\"Debug: Number of active positive target names: {len(active_pos_target_names)}\")\n",
    "\n",
    "    report_pos_str = classification_report(\n",
    "        y_human_pos,\n",
    "        y_gemini_pos,\n",
    "        labels=active_pos_class_indices,  # These are the column indices to report on\n",
    "        target_names=active_pos_target_names, # Names corresponding to these indices\n",
    "        zero_division=0,\n",
    "        output_dict=False\n",
    "    )\n",
    "    print(report_pos_str)\n",
    "\n",
    "\n",
    "print(\"\\n--- Classification Report for NEGATIVE Topics ---\")\n",
    "# Similar logic for negative topics\n",
    "active_neg_class_indices = [\n",
    "    i for i, active in enumerate((y_human_neg.sum(axis=0) + y_gemini_neg.sum(axis=0)) > 0) if active\n",
    "]\n",
    "\n",
    "if not active_neg_class_indices:\n",
    "    print(\"No negative topics found in either human or Gemini labels. Skipping negative report or reporting on all.\")\n",
    "    active_neg_class_indices = list(range(len(mlb.classes_)))\n",
    "    if not active_neg_class_indices:\n",
    "        report_neg_str = \"No topics defined in MLB, cannot generate report.\"\n",
    "        print(report_neg_str)\n",
    "    else:\n",
    "        active_neg_target_names = mlb.classes_\n",
    "        report_neg_str = classification_report(\n",
    "            y_human_neg,\n",
    "            y_gemini_neg,\n",
    "            labels=active_neg_class_indices,\n",
    "            target_names=active_neg_target_names,\n",
    "            zero_division=0,\n",
    "            output_dict=False\n",
    "        )\n",
    "        print(report_neg_str)\n",
    "else:\n",
    "    active_neg_target_names = [mlb.classes_[i] for i in active_neg_class_indices]\n",
    "\n",
    "    print(f\"Debug: Number of active negative class indices: {len(active_neg_class_indices)}\")\n",
    "    print(f\"Debug: Number of active negative target names: {len(active_neg_target_names)}\")\n",
    "\n",
    "    report_neg_str = classification_report(\n",
    "        y_human_neg,\n",
    "        y_gemini_neg,\n",
    "        labels=active_neg_class_indices,\n",
    "        target_names=active_neg_target_names,\n",
    "        zero_division=0,\n",
    "        output_dict=False\n",
    "    )\n",
    "    print(report_neg_str)\n",
    "\n",
    "# --- 9. Save Output ---\n",
    "def list_to_str(lst):\n",
    "    if isinstance(lst, list):\n",
    "        return \";\".join(sorted(list(set(lst)))) # Sort and unique for consistent output\n",
    "    return \"\"\n",
    "\n",
    "df_to_save = merged_df.copy()\n",
    "df_to_save['Gemini_Positive_Topics_Str'] = df_to_save['Gemini_Positive_Topics']\n",
    "df_to_save['Gemini_Negative_Topics_Str'] = df_to_save['Gemini_Negative_Topics']\n",
    "output_columns = [\n",
    "    'SentenceID', 'SentenceText',\n",
    "    'Human_Positive_Topics', 'Human_Negative_Topics',\n",
    "    'Gemini_Positive_Topics_Str', 'Gemini_Negative_Topics_Str'\n",
    "]\n",
    "df_to_save = df_to_save[output_columns]\n",
    "\n",
    "try:\n",
    "    df_to_save.to_csv(OUTPUT_CSV_WITH_GEMINI_LABELS, index=False)\n",
    "    print(f\"\\nSuccessfully saved Gemini's labels and comparison to '{OUTPUT_CSV_WITH_GEMINI_LABELS}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving output CSV: {e}\")\n",
    "\n",
    "print(\"\\n--- Script Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f4157",
   "metadata": {},
   "source": [
    "# OPTIMAL MATCHING BEGINS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7e3a24",
   "metadata": {},
   "source": [
    "## Settting up dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd2af6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students Dataset:\n",
      "   SentenceID                                       SentenceText  \\\n",
      "0           1  I'm really passionate about developing intelli...   \n",
      "1           2  For my capstone project, I'm drawn to creating...   \n",
      "2           3  I'm eager to work on sustainable computing sol...   \n",
      "3           4  My interests lie in developing mobile apps and...   \n",
      "4           5  I'm fascinated by computer vision applications...   \n",
      "\n",
      "                               Human_Positive_Topics  \\\n",
      "0     ['Artificial Intelligence', 'Neural Networks']   \n",
      "1  ['Virtual Reality', 'Augmented Reality', 'Exte...   \n",
      "2              ['Green Computing', 'Sustainability']   \n",
      "3  ['Mobile Application Development', 'UI/UX Desi...   \n",
      "4            ['Computer Vision', 'Image Processing']   \n",
      "\n",
      "                               Human_Negative_Topics  \\\n",
      "0     ['Distributed Systems', 'Computer Networking']   \n",
      "1         ['Fiber Optic Sensor', 'Photonic Devices']   \n",
      "2  ['Blockchain', 'Cybersecurity', 'Information S...   \n",
      "3  ['Big Data Analysis', 'Statistics', 'Time Seri...   \n",
      "4         ['Embedded Systems', 'Internet of Things']   \n",
      "\n",
      "                          Gemini_Positive_Topics_Str  \\\n",
      "0     ['Artificial Intelligence', 'Neural Networks']   \n",
      "1  ['Virtual Reality', 'Augmented Reality', 'Exte...   \n",
      "2                 ['Green Computing', 'Environment']   \n",
      "3             ['Mobile Development', 'UX/UI Design']   \n",
      "4  ['Computer Vision', 'Image Processing', 'Artif...   \n",
      "\n",
      "                          Gemini_Negative_Topics_Str student_id programme  \n",
      "0     ['Distributed Systems', 'Computer Networking']  student_1       BSE  \n",
      "1         ['Fiber Optic Sensor', 'Photonic Devices']  student_2       BIT  \n",
      "2  ['Blockchain', 'Cybersecurity', 'Information S...  student_3       BSE  \n",
      "3         ['Data Analytics', 'Time Series Analysis']  student_4       BCS  \n",
      "4         ['Embedded Systems', 'Internet of Things']  student_5       BCS  \n",
      "\n",
      "Supervisors Dataset:\n",
      "                                      Name Department  \\\n",
      "0                        Ali Afzalian Mand      DDSAI   \n",
      "1  Assoc. Prof. Dr Anwar P.P. Abdul Majeed      DDSAI   \n",
      "2           Assoc. Prof. Dr Azam Che Idris      DDSAI   \n",
      "3  Assoc. Prof. Dr Muhammed Basheer Jasser      DDSAI   \n",
      "4           Assoc. Prof. Dr Aslina Baharum      DDSAI   \n",
      "\n",
      "  Preferred Programme for Supervision (1st Choice)  \\\n",
      "0                                    No Preference   \n",
      "1                                             BSDA   \n",
      "2                                             BSDA   \n",
      "3                                  BCS / BSE / BIT   \n",
      "4                                  BCS / BSE / BIT   \n",
      "\n",
      "  Preferred Programme for Supervision (2nd Choice)  \\\n",
      "0                                    No Preference   \n",
      "1                                  BCS / BSE / BIT   \n",
      "2                                  BCS / BSE / BIT   \n",
      "3                                             BSDA   \n",
      "4                                             BSDA   \n",
      "\n",
      "                                    Expertise Area 1  \\\n",
      "0                        ['Machine Learning Theory']   \n",
      "1              ['Machine Learning', 'Deep Learning']   \n",
      "2              ['DEEP LEARNING', 'MACHINE LEARNING']   \n",
      "3    ['Machine Learning', 'Artificial Intelligence']   \n",
      "4  ['AI-UX', 'UX/UI Research & Design', 'HCI', 'I...   \n",
      "\n",
      "                                    Expertise Area 2  \\\n",
      "0                              ['AI for Healthcare']   \n",
      "1                                 ['Data Analytics']   \n",
      "2                           ['TIME SERIES ANALYSIS']   \n",
      "3               ['Swarm and Evolutionary Computing']   \n",
      "4  ['Software Engineering & Development', 'Inform...   \n",
      "\n",
      "                                    Expertise Area 3  \\\n",
      "0               ['Deep Learning', 'Neural Networks']   \n",
      "1                                       ['Robotics']   \n",
      "2                                ['COMPUTER VISION']   \n",
      "3      ['Software Engineering', 'Software Modeling']   \n",
      "4  ['Information and Communication Technology (IC...   \n",
      "\n",
      "                            standardised Expertise 1  \\\n",
      "0                               ['Machine Learning']   \n",
      "1              ['Machine Learning', 'Deep Learning']   \n",
      "2              ['Deep Learning', 'Machine Learning']   \n",
      "3    ['Machine Learning', 'Artificial Intelligence']   \n",
      "4  ['UX/UI Design', 'UX/UI Design', 'Human-Comput...   \n",
      "\n",
      "                            standardised Expertise 2  \\\n",
      "0                              ['AI for Healthcare']   \n",
      "1                                 ['Data Analytics']   \n",
      "2                           ['Time Series Analysis']   \n",
      "3               ['Swarm and Evolutionary Computing']   \n",
      "4  ['Software Engineering', 'Information Visualiz...   \n",
      "\n",
      "                           standardised Expertise 3  \\\n",
      "0              ['Deep Learning', 'Neural Networks']   \n",
      "1                                      ['Robotics']   \n",
      "2                               ['Computer Vision']   \n",
      "3  ['Software Engineering', 'Software Engineering']   \n",
      "4    ['Information Technology', 'Computer Science']   \n",
      "\n",
      "                                 standardised Topics  supervisor_id  capacity  \n",
      "0  Machine Learning, AI for Healthcare, Deep Lear...              1         9  \n",
      "1  Machine Learning, Deep Learning, Data Analytic...              2         5  \n",
      "2  Deep Learning, Machine Learning, Time Series A...              3         4  \n",
      "3  Machine Learning, Artificial Intelligence, Swa...              4         7  \n",
      "4  UX/UI Design, Human-Computer Interaction, Inte...              5         5  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Import supervisors data and process topics as lists\n",
    "supervisors_df = pd.read_csv('data\\\\supervisors_standardised_gemini.csv')\n",
    "\n",
    "# Update supervisors_df to ensure it has the required columns\n",
    "if 'supervisor_id' not in supervisors_df.columns:\n",
    "    supervisors_df['supervisor_id'] = range(1, len(supervisors_df) + 1)\n",
    "\n",
    "if 'capacity' not in supervisors_df.columns:\n",
    "    supervisors_df['capacity'] = [random.randint(3, 10) for _ in range(len(supervisors_df))]\n",
    "\n",
    "# Generate random students data\n",
    "students_df = pd.read_csv('data\\\\gemini_labeled_preferences.csv')\n",
    "students_df['student_id'] = students_df['SentenceID'].apply(lambda x: f'student_{x}')  # Create unique student IDs\n",
    "students_df['programme'] = students_df['student_id'].apply(\n",
    "    lambda x: random.choice(['BCS', 'BSE', 'BIT', 'BSDA', 'BCNS'])\n",
    ")\n",
    "\n",
    "standardized_topics = pd.read_csv('data\\\\unique_standardised_topics.csv')['standardised Topic'].to_list()\n",
    "\n",
    "def preprocess_topics_from_list(topic_list_series, all_known_topics):\n",
    "    processed_output = []\n",
    "    for topic_list in topic_list_series:\n",
    "        if isinstance(topic_list, list):\n",
    "            valid_topics = [\n",
    "                str(t).strip() for t in topic_list\n",
    "                if isinstance(t, str) and str(t).strip() in all_known_topics\n",
    "            ]\n",
    "            processed_output.append(valid_topics)\n",
    "        else:\n",
    "            processed_output.append([])\n",
    "    return processed_output\n",
    "\n",
    "def human_str_to_list(topic_series, all_known_topics):\n",
    "    processed_list = []\n",
    "    for item in topic_series.fillna(\"\"):\n",
    "        # If already a list, use it directly\n",
    "        if isinstance(item, list):\n",
    "            topics = [str(t).strip() for t in item if str(t).strip()]\n",
    "        # If it's a string representation of a list, safely parse it\n",
    "        elif isinstance(item, str) and item.strip().startswith(\"[\") and item.strip().endswith(\"]\"):\n",
    "            try:\n",
    "                parsed = eval(item)\n",
    "                if isinstance(parsed, list):\n",
    "                    topics = [str(t).strip() for t in parsed if str(t).strip()]\n",
    "                else:\n",
    "                    topics = [str(parsed).strip()] if str(parsed).strip() else []\n",
    "            except Exception:\n",
    "                topics = [item.strip()] if item.strip() else []\n",
    "        elif pd.isna(item) or str(item).lower() == \"none\" or str(item).strip() == \"\":\n",
    "            topics = []\n",
    "        else:\n",
    "            topics = [t.strip() for t in str(item).split(';') if t.strip()]\n",
    "        valid_topics = [t for t in topics if t in all_known_topics]\n",
    "        processed_list.append(valid_topics)\n",
    "    return processed_list\n",
    "\n",
    "def safe_list(val):\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    if isinstance(val, float) or pd.isna(val):\n",
    "        return []\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            # Try to parse stringified list\n",
    "            if val.strip().startswith(\"[\") and val.strip().endswith(\"]\"):\n",
    "                parsed = eval(val)\n",
    "                if isinstance(parsed, list):\n",
    "                    return [str(t).strip() for t in parsed if str(t).strip()]\n",
    "            # Otherwise, split by comma or semicolon\n",
    "            return [t.strip() for t in val.split(',') if t.strip()]\n",
    "        except Exception:\n",
    "            return [val.strip()] if val.strip() else []\n",
    "    return []\n",
    "\n",
    "# Display the datasets\n",
    "print(\"Students Dataset:\")\n",
    "print(students_df.head())\n",
    "print(\"\\nSupervisors Dataset:\")\n",
    "print(supervisors_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7bc59",
   "metadata": {},
   "source": [
    "## Linear Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cac94ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running optimal matching with balancing penalty weight: 10\n",
      "Target load per supervisor (for soft balancing): 3.40\n",
      "\n",
      "Optimal Assignments:\n",
      "      student_id  supervisor_id                            supervisor_name  \\\n",
      "0      student_1             27                   Dr Brandon Khoo Boo Guan   \n",
      "1      student_2             16                    Nurul Aiman Abdul Rahim   \n",
      "2      student_3             39                         Prof. Lau Sian Lun   \n",
      "3      student_4              8                     Dr Faris Syahmi Samidi   \n",
      "4      student_5             27                   Dr Brandon Khoo Boo Guan   \n",
      "..           ...            ...                                        ...   \n",
      "175  student_176             21  Assoc. Prof. Dr Sami Salama Hussen Hajjaj   \n",
      "176  student_177             40                      Prof. Serge Demidenko   \n",
      "177  student_178             24                         Dr Aaliya Sarfaraz   \n",
      "178  student_179             25                 Dr Ahmad Sahban Rafsanjani   \n",
      "179  student_180             43                              Yeap Boon Han   \n",
      "\n",
      "    programme_match                                    matching_topics  \\\n",
      "0      First Choice                          [Artificial Intelligence]   \n",
      "1      First Choice  [Virtual Reality, Augmented Reality, Human-Com...   \n",
      "2      First Choice                                  [Green Computing]   \n",
      "3      First Choice                               [Mobile Development]   \n",
      "4      First Choice         [Computer Vision, Artificial Intelligence]   \n",
      "..              ...                                                ...   \n",
      "175    First Choice                               [Internet of Things]   \n",
      "176    First Choice                             [Software Engineering]   \n",
      "177    First Choice                                       [Blockchain]   \n",
      "178    First Choice                                                 []   \n",
      "179    First Choice                             [Software Engineering]   \n",
      "\n",
      "    conflicting_topics  match_score  \n",
      "0                   []           12  \n",
      "1                   []           16  \n",
      "2                   []           12  \n",
      "3                   []           12  \n",
      "4                   []           14  \n",
      "..                 ...          ...  \n",
      "175                 []           12  \n",
      "176                 []           12  \n",
      "177                 []           12  \n",
      "178                 []           10  \n",
      "179                 []           12  \n",
      "\n",
      "[180 rows x 7 columns]\n",
      "\n",
      "Assignment Statistics:\n",
      "Total assignments: 180\n",
      "\n",
      "Programme Matching Distribution:\n",
      "programme_match\n",
      "First Choice     179\n",
      "Second Choice      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average matching topics: 0.73\n",
      "Average conflicting topics: 0.01\n",
      "Average match score: 11.42\n",
      "Standard Deviation of match scores: 1.49\n",
      "\n",
      "Optimal assignments saved to: results\\OMA\\optimal_student_supervisor_assignments_10.csv\n",
      "\n",
      "Average number of students assigned per supervisor: 3.40\n",
      "Standard Deviation of students assigned per supervisor: 0.49\n",
      "\n",
      "Supervisor Assignments Count:\n",
      "    supervisor_id  assigned_students_count  \\\n",
      "0               1                        4   \n",
      "1               2                        3   \n",
      "2               3                        3   \n",
      "3               4                        4   \n",
      "4               5                        4   \n",
      "5               6                        4   \n",
      "6               7                        3   \n",
      "7               8                        3   \n",
      "8               9                        3   \n",
      "9              10                        4   \n",
      "10             11                        4   \n",
      "11             12                        3   \n",
      "12             13                        3   \n",
      "13             14                        4   \n",
      "14             15                        3   \n",
      "15             16                        4   \n",
      "16             17                        3   \n",
      "17             18                        3   \n",
      "18             19                        4   \n",
      "19             20                        3   \n",
      "20             21                        4   \n",
      "21             22                        3   \n",
      "22             23                        3   \n",
      "23             24                        3   \n",
      "24             25                        4   \n",
      "25             26                        3   \n",
      "26             27                        4   \n",
      "27             28                        3   \n",
      "28             29                        3   \n",
      "29             30                        3   \n",
      "30             31                        3   \n",
      "31             32                        3   \n",
      "32             33                        3   \n",
      "33             34                        3   \n",
      "34             35                        3   \n",
      "35             36                        3   \n",
      "36             37                        3   \n",
      "37             38                        4   \n",
      "38             39                        4   \n",
      "39             40                        3   \n",
      "40             41                        4   \n",
      "41             42                        4   \n",
      "42             43                        4   \n",
      "43             44                        3   \n",
      "44             45                        4   \n",
      "45             46                        3   \n",
      "46             47                        3   \n",
      "47             48                        3   \n",
      "48             49                        4   \n",
      "49             50                        4   \n",
      "50             51                        3   \n",
      "51             52                        3   \n",
      "52             53                        4   \n",
      "\n",
      "                                               Name  \n",
      "0                                 Ali Afzalian Mand  \n",
      "1           Assoc. Prof. Dr Anwar P.P. Abdul Majeed  \n",
      "2                    Assoc. Prof. Dr Azam Che Idris  \n",
      "3           Assoc. Prof. Dr Muhammed Basheer Jasser  \n",
      "4                    Assoc. Prof. Dr Aslina Baharum  \n",
      "5                            Dr Danish Mahmood Khan  \n",
      "6                         Dr David Olayemi Alebiosu  \n",
      "7                            Dr Faris Syahmi Samidi  \n",
      "8                                 Dr Farrukh Hassan  \n",
      "9                                  Dr Hadyan Hafizh  \n",
      "10                       Dr Javid Iqbal Thirupattur  \n",
      "11                           Dr Mohd Firdaus Roslan  \n",
      "12                       Dr Samuel Mofoluwa Ajibade  \n",
      "13  Dr Sathishkumar Veerappampalayam Easwaramoorthy  \n",
      "14                                  Dr Teoh Yun Xin  \n",
      "15                          Nurul Aiman Abdul Rahim  \n",
      "16                      Prof. Angela Lee Siew Hoong  \n",
      "17                                Prof. Chua Hui Na  \n",
      "18                       Assoc. Prof. Dr Saad Aslam  \n",
      "19             Assoc. Prof. Dr Selina Low Yeh Ching  \n",
      "20        Assoc. Prof. Dr Sami Salama Hussen Hajjaj  \n",
      "21                       Assoc. Prof. Dr Lee Yun Li  \n",
      "22                            Charis Kwan Shwu Chen  \n",
      "23                               Dr Aaliya Sarfaraz  \n",
      "24                       Dr Ahmad Sahban Rafsanjani  \n",
      "25                             Dr Azizzeanna Hassan  \n",
      "26                         Dr Brandon Khoo Boo Guan  \n",
      "27                                  Dr Chew Moi Tin  \n",
      "28                                 Dr Chin Teck Min  \n",
      "29                                Dr Ghulam Murtaza  \n",
      "30                               Dr Maisarah Mansor  \n",
      "31                                Dr Mehran Behjati  \n",
      "32                             Dr Melody Tan Shi Ai  \n",
      "33                           Dr Noor Hafizah Hassan  \n",
      "34                     Dr Nor Hafizah Mohamed Halip  \n",
      "35                           Dr Yawar Abbas Bangash  \n",
      "36                                        Foo Jinny  \n",
      "37                                    Lim Woan Ning  \n",
      "38                               Prof. Lau Sian Lun  \n",
      "39                            Prof. Serge Demidenko  \n",
      "40                             Prof. Lee Chien Sing  \n",
      "41                                    Pyi Phyo Aung  \n",
      "42                                    Yeap Boon Han  \n",
      "43        Assoc. Prof. Dr Ranjit Singh Sarban Singh  \n",
      "44                                Dr Tang Tiong Yew  \n",
      "45                              Prof. Yap Kian Meng  \n",
      "46                                  Dr Tan Tee Hean  \n",
      "47                   Assoc. Prof. Dr Chia Wai Chong  \n",
      "48                         Dr Richard Wong Teck Ken  \n",
      "49                                Dr Ngu War Hlaing  \n",
      "50                     Assoc. Prof. Abdul Aziz Omar  \n",
      "51                           Prof. Rosdiadee Nordin  \n",
      "52                              Prof. Liew Chee Sun  \n",
      "\n",
      "Supervisor assignments statistics saved to: results/OMA/supervisor_assignments_statistics.csv\n",
      "\n",
      "Running optimal matching with balancing penalty weight: 100\n",
      "Target load per supervisor (for soft balancing): 3.40\n",
      "\n",
      "Optimal Assignments:\n",
      "      student_id  supervisor_id                            supervisor_name  \\\n",
      "0      student_1             23                      Charis Kwan Shwu Chen   \n",
      "1      student_2             16                    Nurul Aiman Abdul Rahim   \n",
      "2      student_3             39                         Prof. Lau Sian Lun   \n",
      "3      student_4              8                     Dr Faris Syahmi Samidi   \n",
      "4      student_5             27                   Dr Brandon Khoo Boo Guan   \n",
      "..           ...            ...                                        ...   \n",
      "175  student_176             21  Assoc. Prof. Dr Sami Salama Hussen Hajjaj   \n",
      "176  student_177              9                          Dr Farrukh Hassan   \n",
      "177  student_178             45                          Dr Tang Tiong Yew   \n",
      "178  student_179             49                   Dr Richard Wong Teck Ken   \n",
      "179  student_180             29                           Dr Chin Teck Min   \n",
      "\n",
      "    programme_match                                    matching_topics  \\\n",
      "0      First Choice                          [Artificial Intelligence]   \n",
      "1      First Choice  [Virtual Reality, Augmented Reality, Human-Com...   \n",
      "2      First Choice                                  [Green Computing]   \n",
      "3      First Choice                               [Mobile Development]   \n",
      "4      First Choice         [Computer Vision, Artificial Intelligence]   \n",
      "..              ...                                                ...   \n",
      "175    First Choice                               [Internet of Things]   \n",
      "176    First Choice                                                 []   \n",
      "177    First Choice                                       [Blockchain]   \n",
      "178    First Choice                                                 []   \n",
      "179    First Choice                             [Software Engineering]   \n",
      "\n",
      "    conflicting_topics  match_score  \n",
      "0                   []           12  \n",
      "1                   []           16  \n",
      "2                   []           12  \n",
      "3                   []           12  \n",
      "4                   []           14  \n",
      "..                 ...          ...  \n",
      "175                 []           12  \n",
      "176                 []           10  \n",
      "177                 []           12  \n",
      "178                 []           10  \n",
      "179                 []           12  \n",
      "\n",
      "[180 rows x 7 columns]\n",
      "\n",
      "Assignment Statistics:\n",
      "Total assignments: 180\n",
      "\n",
      "Programme Matching Distribution:\n",
      "programme_match\n",
      "First Choice     179\n",
      "Second Choice      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average matching topics: 0.73\n",
      "Average conflicting topics: 0.01\n",
      "Average match score: 11.42\n",
      "Standard Deviation of match scores: 1.48\n",
      "\n",
      "Optimal assignments saved to: results\\OMA\\optimal_student_supervisor_assignments_100.csv\n",
      "\n",
      "Average number of students assigned per supervisor: 3.40\n",
      "Standard Deviation of students assigned per supervisor: 0.49\n",
      "\n",
      "Supervisor Assignments Count:\n",
      "    supervisor_id  assigned_students_count  \\\n",
      "0               1                        3   \n",
      "1               2                        3   \n",
      "2               3                        3   \n",
      "3               4                        3   \n",
      "4               5                        3   \n",
      "5               6                        4   \n",
      "6               7                        4   \n",
      "7               8                        4   \n",
      "8               9                        3   \n",
      "9              10                        3   \n",
      "10             11                        3   \n",
      "11             12                        4   \n",
      "12             13                        3   \n",
      "13             14                        4   \n",
      "14             15                        4   \n",
      "15             16                        4   \n",
      "16             17                        3   \n",
      "17             18                        3   \n",
      "18             19                        4   \n",
      "19             20                        3   \n",
      "20             21                        4   \n",
      "21             22                        3   \n",
      "22             23                        4   \n",
      "23             24                        3   \n",
      "24             25                        3   \n",
      "25             26                        3   \n",
      "26             27                        4   \n",
      "27             28                        4   \n",
      "28             29                        4   \n",
      "29             30                        3   \n",
      "30             31                        3   \n",
      "31             32                        3   \n",
      "32             33                        3   \n",
      "33             34                        3   \n",
      "34             35                        3   \n",
      "35             36                        3   \n",
      "36             37                        3   \n",
      "37             38                        4   \n",
      "38             39                        4   \n",
      "39             40                        4   \n",
      "40             41                        4   \n",
      "41             42                        3   \n",
      "42             43                        3   \n",
      "43             44                        3   \n",
      "44             45                        4   \n",
      "45             46                        4   \n",
      "46             47                        3   \n",
      "47             48                        3   \n",
      "48             49                        4   \n",
      "49             50                        3   \n",
      "50             51                        3   \n",
      "51             52                        3   \n",
      "52             53                        4   \n",
      "\n",
      "                                               Name  \n",
      "0                                 Ali Afzalian Mand  \n",
      "1           Assoc. Prof. Dr Anwar P.P. Abdul Majeed  \n",
      "2                    Assoc. Prof. Dr Azam Che Idris  \n",
      "3           Assoc. Prof. Dr Muhammed Basheer Jasser  \n",
      "4                    Assoc. Prof. Dr Aslina Baharum  \n",
      "5                            Dr Danish Mahmood Khan  \n",
      "6                         Dr David Olayemi Alebiosu  \n",
      "7                            Dr Faris Syahmi Samidi  \n",
      "8                                 Dr Farrukh Hassan  \n",
      "9                                  Dr Hadyan Hafizh  \n",
      "10                       Dr Javid Iqbal Thirupattur  \n",
      "11                           Dr Mohd Firdaus Roslan  \n",
      "12                       Dr Samuel Mofoluwa Ajibade  \n",
      "13  Dr Sathishkumar Veerappampalayam Easwaramoorthy  \n",
      "14                                  Dr Teoh Yun Xin  \n",
      "15                          Nurul Aiman Abdul Rahim  \n",
      "16                      Prof. Angela Lee Siew Hoong  \n",
      "17                                Prof. Chua Hui Na  \n",
      "18                       Assoc. Prof. Dr Saad Aslam  \n",
      "19             Assoc. Prof. Dr Selina Low Yeh Ching  \n",
      "20        Assoc. Prof. Dr Sami Salama Hussen Hajjaj  \n",
      "21                       Assoc. Prof. Dr Lee Yun Li  \n",
      "22                            Charis Kwan Shwu Chen  \n",
      "23                               Dr Aaliya Sarfaraz  \n",
      "24                       Dr Ahmad Sahban Rafsanjani  \n",
      "25                             Dr Azizzeanna Hassan  \n",
      "26                         Dr Brandon Khoo Boo Guan  \n",
      "27                                  Dr Chew Moi Tin  \n",
      "28                                 Dr Chin Teck Min  \n",
      "29                                Dr Ghulam Murtaza  \n",
      "30                               Dr Maisarah Mansor  \n",
      "31                                Dr Mehran Behjati  \n",
      "32                             Dr Melody Tan Shi Ai  \n",
      "33                           Dr Noor Hafizah Hassan  \n",
      "34                     Dr Nor Hafizah Mohamed Halip  \n",
      "35                           Dr Yawar Abbas Bangash  \n",
      "36                                        Foo Jinny  \n",
      "37                                    Lim Woan Ning  \n",
      "38                               Prof. Lau Sian Lun  \n",
      "39                            Prof. Serge Demidenko  \n",
      "40                             Prof. Lee Chien Sing  \n",
      "41                                    Pyi Phyo Aung  \n",
      "42                                    Yeap Boon Han  \n",
      "43        Assoc. Prof. Dr Ranjit Singh Sarban Singh  \n",
      "44                                Dr Tang Tiong Yew  \n",
      "45                              Prof. Yap Kian Meng  \n",
      "46                                  Dr Tan Tee Hean  \n",
      "47                   Assoc. Prof. Dr Chia Wai Chong  \n",
      "48                         Dr Richard Wong Teck Ken  \n",
      "49                                Dr Ngu War Hlaing  \n",
      "50                     Assoc. Prof. Abdul Aziz Omar  \n",
      "51                           Prof. Rosdiadee Nordin  \n",
      "52                              Prof. Liew Chee Sun  \n",
      "\n",
      "Supervisor assignments statistics saved to: results/OMA/supervisor_assignments_statistics.csv\n",
      "\n",
      "Running optimal matching with balancing penalty weight: 1000\n",
      "Target load per supervisor (for soft balancing): 3.40\n",
      "\n",
      "Optimal Assignments:\n",
      "      student_id  supervisor_id                            supervisor_name  \\\n",
      "0      student_1             23                      Charis Kwan Shwu Chen   \n",
      "1      student_2             16                    Nurul Aiman Abdul Rahim   \n",
      "2      student_3             39                         Prof. Lau Sian Lun   \n",
      "3      student_4              8                     Dr Faris Syahmi Samidi   \n",
      "4      student_5             27                   Dr Brandon Khoo Boo Guan   \n",
      "..           ...            ...                                        ...   \n",
      "175  student_176             21  Assoc. Prof. Dr Sami Salama Hussen Hajjaj   \n",
      "176  student_177              9                          Dr Farrukh Hassan   \n",
      "177  student_178             45                          Dr Tang Tiong Yew   \n",
      "178  student_179             49                   Dr Richard Wong Teck Ken   \n",
      "179  student_180             29                           Dr Chin Teck Min   \n",
      "\n",
      "    programme_match                                    matching_topics  \\\n",
      "0      First Choice                          [Artificial Intelligence]   \n",
      "1      First Choice  [Virtual Reality, Augmented Reality, Human-Com...   \n",
      "2      First Choice                                  [Green Computing]   \n",
      "3      First Choice                               [Mobile Development]   \n",
      "4      First Choice         [Computer Vision, Artificial Intelligence]   \n",
      "..              ...                                                ...   \n",
      "175    First Choice                               [Internet of Things]   \n",
      "176    First Choice                                                 []   \n",
      "177    First Choice                                       [Blockchain]   \n",
      "178    First Choice                                                 []   \n",
      "179    First Choice                             [Software Engineering]   \n",
      "\n",
      "    conflicting_topics  match_score  \n",
      "0                   []           12  \n",
      "1                   []           16  \n",
      "2                   []           12  \n",
      "3                   []           12  \n",
      "4                   []           14  \n",
      "..                 ...          ...  \n",
      "175                 []           12  \n",
      "176                 []           10  \n",
      "177                 []           12  \n",
      "178                 []           10  \n",
      "179                 []           12  \n",
      "\n",
      "[180 rows x 7 columns]\n",
      "\n",
      "Assignment Statistics:\n",
      "Total assignments: 180\n",
      "\n",
      "Programme Matching Distribution:\n",
      "programme_match\n",
      "First Choice     179\n",
      "Second Choice      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average matching topics: 0.73\n",
      "Average conflicting topics: 0.01\n",
      "Average match score: 11.42\n",
      "Standard Deviation of match scores: 1.48\n",
      "\n",
      "Optimal assignments saved to: results\\OMA\\optimal_student_supervisor_assignments_1000.csv\n",
      "\n",
      "Average number of students assigned per supervisor: 3.40\n",
      "Standard Deviation of students assigned per supervisor: 0.49\n",
      "\n",
      "Supervisor Assignments Count:\n",
      "    supervisor_id  assigned_students_count  \\\n",
      "0               1                        3   \n",
      "1               2                        3   \n",
      "2               3                        3   \n",
      "3               4                        3   \n",
      "4               5                        3   \n",
      "5               6                        4   \n",
      "6               7                        4   \n",
      "7               8                        3   \n",
      "8               9                        3   \n",
      "9              10                        4   \n",
      "10             11                        3   \n",
      "11             12                        4   \n",
      "12             13                        3   \n",
      "13             14                        4   \n",
      "14             15                        4   \n",
      "15             16                        4   \n",
      "16             17                        3   \n",
      "17             18                        3   \n",
      "18             19                        3   \n",
      "19             20                        3   \n",
      "20             21                        4   \n",
      "21             22                        3   \n",
      "22             23                        4   \n",
      "23             24                        3   \n",
      "24             25                        3   \n",
      "25             26                        4   \n",
      "26             27                        4   \n",
      "27             28                        4   \n",
      "28             29                        3   \n",
      "29             30                        3   \n",
      "30             31                        3   \n",
      "31             32                        3   \n",
      "32             33                        3   \n",
      "33             34                        3   \n",
      "34             35                        3   \n",
      "35             36                        3   \n",
      "36             37                        3   \n",
      "37             38                        4   \n",
      "38             39                        4   \n",
      "39             40                        4   \n",
      "40             41                        4   \n",
      "41             42                        3   \n",
      "42             43                        4   \n",
      "43             44                        3   \n",
      "44             45                        4   \n",
      "45             46                        4   \n",
      "46             47                        3   \n",
      "47             48                        3   \n",
      "48             49                        4   \n",
      "49             50                        3   \n",
      "50             51                        3   \n",
      "51             52                        3   \n",
      "52             53                        4   \n",
      "\n",
      "                                               Name  \n",
      "0                                 Ali Afzalian Mand  \n",
      "1           Assoc. Prof. Dr Anwar P.P. Abdul Majeed  \n",
      "2                    Assoc. Prof. Dr Azam Che Idris  \n",
      "3           Assoc. Prof. Dr Muhammed Basheer Jasser  \n",
      "4                    Assoc. Prof. Dr Aslina Baharum  \n",
      "5                            Dr Danish Mahmood Khan  \n",
      "6                         Dr David Olayemi Alebiosu  \n",
      "7                            Dr Faris Syahmi Samidi  \n",
      "8                                 Dr Farrukh Hassan  \n",
      "9                                  Dr Hadyan Hafizh  \n",
      "10                       Dr Javid Iqbal Thirupattur  \n",
      "11                           Dr Mohd Firdaus Roslan  \n",
      "12                       Dr Samuel Mofoluwa Ajibade  \n",
      "13  Dr Sathishkumar Veerappampalayam Easwaramoorthy  \n",
      "14                                  Dr Teoh Yun Xin  \n",
      "15                          Nurul Aiman Abdul Rahim  \n",
      "16                      Prof. Angela Lee Siew Hoong  \n",
      "17                                Prof. Chua Hui Na  \n",
      "18                       Assoc. Prof. Dr Saad Aslam  \n",
      "19             Assoc. Prof. Dr Selina Low Yeh Ching  \n",
      "20        Assoc. Prof. Dr Sami Salama Hussen Hajjaj  \n",
      "21                       Assoc. Prof. Dr Lee Yun Li  \n",
      "22                            Charis Kwan Shwu Chen  \n",
      "23                               Dr Aaliya Sarfaraz  \n",
      "24                       Dr Ahmad Sahban Rafsanjani  \n",
      "25                             Dr Azizzeanna Hassan  \n",
      "26                         Dr Brandon Khoo Boo Guan  \n",
      "27                                  Dr Chew Moi Tin  \n",
      "28                                 Dr Chin Teck Min  \n",
      "29                                Dr Ghulam Murtaza  \n",
      "30                               Dr Maisarah Mansor  \n",
      "31                                Dr Mehran Behjati  \n",
      "32                             Dr Melody Tan Shi Ai  \n",
      "33                           Dr Noor Hafizah Hassan  \n",
      "34                     Dr Nor Hafizah Mohamed Halip  \n",
      "35                           Dr Yawar Abbas Bangash  \n",
      "36                                        Foo Jinny  \n",
      "37                                    Lim Woan Ning  \n",
      "38                               Prof. Lau Sian Lun  \n",
      "39                            Prof. Serge Demidenko  \n",
      "40                             Prof. Lee Chien Sing  \n",
      "41                                    Pyi Phyo Aung  \n",
      "42                                    Yeap Boon Han  \n",
      "43        Assoc. Prof. Dr Ranjit Singh Sarban Singh  \n",
      "44                                Dr Tang Tiong Yew  \n",
      "45                              Prof. Yap Kian Meng  \n",
      "46                                  Dr Tan Tee Hean  \n",
      "47                   Assoc. Prof. Dr Chia Wai Chong  \n",
      "48                         Dr Richard Wong Teck Ken  \n",
      "49                                Dr Ngu War Hlaing  \n",
      "50                     Assoc. Prof. Abdul Aziz Omar  \n",
      "51                           Prof. Rosdiadee Nordin  \n",
      "52                              Prof. Liew Chee Sun  \n",
      "\n",
      "Supervisor assignments statistics saved to: results/OMA/supervisor_assignments_statistics.csv\n",
      "\n",
      "Running optimal matching with balancing penalty weight: 10000\n",
      "Target load per supervisor (for soft balancing): 3.40\n",
      "\n",
      "Optimal Assignments:\n",
      "      student_id  supervisor_id                            supervisor_name  \\\n",
      "0      student_1             23                      Charis Kwan Shwu Chen   \n",
      "1      student_2             16                    Nurul Aiman Abdul Rahim   \n",
      "2      student_3             39                         Prof. Lau Sian Lun   \n",
      "3      student_4              8                     Dr Faris Syahmi Samidi   \n",
      "4      student_5             27                   Dr Brandon Khoo Boo Guan   \n",
      "..           ...            ...                                        ...   \n",
      "175  student_176             21  Assoc. Prof. Dr Sami Salama Hussen Hajjaj   \n",
      "176  student_177              9                          Dr Farrukh Hassan   \n",
      "177  student_178             45                          Dr Tang Tiong Yew   \n",
      "178  student_179             49                   Dr Richard Wong Teck Ken   \n",
      "179  student_180             29                           Dr Chin Teck Min   \n",
      "\n",
      "    programme_match                                    matching_topics  \\\n",
      "0      First Choice                          [Artificial Intelligence]   \n",
      "1      First Choice  [Virtual Reality, Augmented Reality, Human-Com...   \n",
      "2      First Choice                                  [Green Computing]   \n",
      "3      First Choice                               [Mobile Development]   \n",
      "4      First Choice         [Computer Vision, Artificial Intelligence]   \n",
      "..              ...                                                ...   \n",
      "175    First Choice                               [Internet of Things]   \n",
      "176    First Choice                                                 []   \n",
      "177    First Choice                                       [Blockchain]   \n",
      "178    First Choice                                                 []   \n",
      "179    First Choice                             [Software Engineering]   \n",
      "\n",
      "    conflicting_topics  match_score  \n",
      "0                   []           12  \n",
      "1                   []           16  \n",
      "2                   []           12  \n",
      "3                   []           12  \n",
      "4                   []           14  \n",
      "..                 ...          ...  \n",
      "175                 []           12  \n",
      "176                 []           10  \n",
      "177                 []           12  \n",
      "178                 []           10  \n",
      "179                 []           12  \n",
      "\n",
      "[180 rows x 7 columns]\n",
      "\n",
      "Assignment Statistics:\n",
      "Total assignments: 180\n",
      "\n",
      "Programme Matching Distribution:\n",
      "programme_match\n",
      "First Choice     179\n",
      "Second Choice      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average matching topics: 0.73\n",
      "Average conflicting topics: 0.01\n",
      "Average match score: 11.42\n",
      "Standard Deviation of match scores: 1.48\n",
      "\n",
      "Optimal assignments saved to: results\\OMA\\optimal_student_supervisor_assignments_10000.csv\n",
      "\n",
      "Average number of students assigned per supervisor: 3.40\n",
      "Standard Deviation of students assigned per supervisor: 0.49\n",
      "\n",
      "Supervisor Assignments Count:\n",
      "    supervisor_id  assigned_students_count  \\\n",
      "0               1                        3   \n",
      "1               2                        3   \n",
      "2               3                        3   \n",
      "3               4                        3   \n",
      "4               5                        3   \n",
      "5               6                        4   \n",
      "6               7                        4   \n",
      "7               8                        3   \n",
      "8               9                        3   \n",
      "9              10                        3   \n",
      "10             11                        3   \n",
      "11             12                        4   \n",
      "12             13                        3   \n",
      "13             14                        4   \n",
      "14             15                        4   \n",
      "15             16                        4   \n",
      "16             17                        3   \n",
      "17             18                        3   \n",
      "18             19                        3   \n",
      "19             20                        3   \n",
      "20             21                        4   \n",
      "21             22                        3   \n",
      "22             23                        4   \n",
      "23             24                        3   \n",
      "24             25                        3   \n",
      "25             26                        4   \n",
      "26             27                        4   \n",
      "27             28                        4   \n",
      "28             29                        4   \n",
      "29             30                        3   \n",
      "30             31                        3   \n",
      "31             32                        3   \n",
      "32             33                        3   \n",
      "33             34                        3   \n",
      "34             35                        3   \n",
      "35             36                        3   \n",
      "36             37                        3   \n",
      "37             38                        4   \n",
      "38             39                        4   \n",
      "39             40                        4   \n",
      "40             41                        4   \n",
      "41             42                        3   \n",
      "42             43                        4   \n",
      "43             44                        3   \n",
      "44             45                        4   \n",
      "45             46                        4   \n",
      "46             47                        3   \n",
      "47             48                        3   \n",
      "48             49                        4   \n",
      "49             50                        3   \n",
      "50             51                        3   \n",
      "51             52                        3   \n",
      "52             53                        4   \n",
      "\n",
      "                                               Name  \n",
      "0                                 Ali Afzalian Mand  \n",
      "1           Assoc. Prof. Dr Anwar P.P. Abdul Majeed  \n",
      "2                    Assoc. Prof. Dr Azam Che Idris  \n",
      "3           Assoc. Prof. Dr Muhammed Basheer Jasser  \n",
      "4                    Assoc. Prof. Dr Aslina Baharum  \n",
      "5                            Dr Danish Mahmood Khan  \n",
      "6                         Dr David Olayemi Alebiosu  \n",
      "7                            Dr Faris Syahmi Samidi  \n",
      "8                                 Dr Farrukh Hassan  \n",
      "9                                  Dr Hadyan Hafizh  \n",
      "10                       Dr Javid Iqbal Thirupattur  \n",
      "11                           Dr Mohd Firdaus Roslan  \n",
      "12                       Dr Samuel Mofoluwa Ajibade  \n",
      "13  Dr Sathishkumar Veerappampalayam Easwaramoorthy  \n",
      "14                                  Dr Teoh Yun Xin  \n",
      "15                          Nurul Aiman Abdul Rahim  \n",
      "16                      Prof. Angela Lee Siew Hoong  \n",
      "17                                Prof. Chua Hui Na  \n",
      "18                       Assoc. Prof. Dr Saad Aslam  \n",
      "19             Assoc. Prof. Dr Selina Low Yeh Ching  \n",
      "20        Assoc. Prof. Dr Sami Salama Hussen Hajjaj  \n",
      "21                       Assoc. Prof. Dr Lee Yun Li  \n",
      "22                            Charis Kwan Shwu Chen  \n",
      "23                               Dr Aaliya Sarfaraz  \n",
      "24                       Dr Ahmad Sahban Rafsanjani  \n",
      "25                             Dr Azizzeanna Hassan  \n",
      "26                         Dr Brandon Khoo Boo Guan  \n",
      "27                                  Dr Chew Moi Tin  \n",
      "28                                 Dr Chin Teck Min  \n",
      "29                                Dr Ghulam Murtaza  \n",
      "30                               Dr Maisarah Mansor  \n",
      "31                                Dr Mehran Behjati  \n",
      "32                             Dr Melody Tan Shi Ai  \n",
      "33                           Dr Noor Hafizah Hassan  \n",
      "34                     Dr Nor Hafizah Mohamed Halip  \n",
      "35                           Dr Yawar Abbas Bangash  \n",
      "36                                        Foo Jinny  \n",
      "37                                    Lim Woan Ning  \n",
      "38                               Prof. Lau Sian Lun  \n",
      "39                            Prof. Serge Demidenko  \n",
      "40                             Prof. Lee Chien Sing  \n",
      "41                                    Pyi Phyo Aung  \n",
      "42                                    Yeap Boon Han  \n",
      "43        Assoc. Prof. Dr Ranjit Singh Sarban Singh  \n",
      "44                                Dr Tang Tiong Yew  \n",
      "45                              Prof. Yap Kian Meng  \n",
      "46                                  Dr Tan Tee Hean  \n",
      "47                   Assoc. Prof. Dr Chia Wai Chong  \n",
      "48                         Dr Richard Wong Teck Ken  \n",
      "49                                Dr Ngu War Hlaing  \n",
      "50                     Assoc. Prof. Abdul Aziz Omar  \n",
      "51                           Prof. Rosdiadee Nordin  \n",
      "52                              Prof. Liew Chee Sun  \n",
      "\n",
      "Supervisor assignments statistics saved to: results/OMA/supervisor_assignments_statistics.csv\n",
      "\n",
      "Running optimal matching with balancing penalty weight: 100000\n",
      "Target load per supervisor (for soft balancing): 3.40\n",
      "\n",
      "Optimal Assignments:\n",
      "      student_id  supervisor_id                            supervisor_name  \\\n",
      "0      student_1             23                      Charis Kwan Shwu Chen   \n",
      "1      student_2             16                    Nurul Aiman Abdul Rahim   \n",
      "2      student_3             39                         Prof. Lau Sian Lun   \n",
      "3      student_4              8                     Dr Faris Syahmi Samidi   \n",
      "4      student_5             27                   Dr Brandon Khoo Boo Guan   \n",
      "..           ...            ...                                        ...   \n",
      "175  student_176             21  Assoc. Prof. Dr Sami Salama Hussen Hajjaj   \n",
      "176  student_177              9                          Dr Farrukh Hassan   \n",
      "177  student_178             24                         Dr Aaliya Sarfaraz   \n",
      "178  student_179             25                 Dr Ahmad Sahban Rafsanjani   \n",
      "179  student_180             29                           Dr Chin Teck Min   \n",
      "\n",
      "    programme_match                                    matching_topics  \\\n",
      "0      First Choice                          [Artificial Intelligence]   \n",
      "1      First Choice  [Virtual Reality, Augmented Reality, Human-Com...   \n",
      "2      First Choice                                  [Green Computing]   \n",
      "3      First Choice                               [Mobile Development]   \n",
      "4      First Choice         [Computer Vision, Artificial Intelligence]   \n",
      "..              ...                                                ...   \n",
      "175    First Choice                               [Internet of Things]   \n",
      "176    First Choice                                                 []   \n",
      "177    First Choice                                       [Blockchain]   \n",
      "178    First Choice                                                 []   \n",
      "179    First Choice                             [Software Engineering]   \n",
      "\n",
      "    conflicting_topics  match_score  \n",
      "0                   []           12  \n",
      "1                   []           16  \n",
      "2                   []           12  \n",
      "3                   []           12  \n",
      "4                   []           14  \n",
      "..                 ...          ...  \n",
      "175                 []           12  \n",
      "176                 []           10  \n",
      "177                 []           12  \n",
      "178                 []           10  \n",
      "179                 []           12  \n",
      "\n",
      "[180 rows x 7 columns]\n",
      "\n",
      "Assignment Statistics:\n",
      "Total assignments: 180\n",
      "\n",
      "Programme Matching Distribution:\n",
      "programme_match\n",
      "First Choice     179\n",
      "Second Choice      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Average matching topics: 0.73\n",
      "Average conflicting topics: 0.01\n",
      "Average match score: 11.42\n",
      "Standard Deviation of match scores: 1.48\n",
      "\n",
      "Optimal assignments saved to: results\\OMA\\optimal_student_supervisor_assignments_100000.csv\n",
      "\n",
      "Average number of students assigned per supervisor: 3.40\n",
      "Standard Deviation of students assigned per supervisor: 0.49\n",
      "\n",
      "Supervisor Assignments Count:\n",
      "    supervisor_id  assigned_students_count  \\\n",
      "0               1                        3   \n",
      "1               2                        3   \n",
      "2               3                        3   \n",
      "3               4                        3   \n",
      "4               5                        3   \n",
      "5               6                        4   \n",
      "6               7                        3   \n",
      "7               8                        4   \n",
      "8               9                        3   \n",
      "9              10                        4   \n",
      "10             11                        3   \n",
      "11             12                        4   \n",
      "12             13                        3   \n",
      "13             14                        4   \n",
      "14             15                        4   \n",
      "15             16                        4   \n",
      "16             17                        3   \n",
      "17             18                        3   \n",
      "18             19                        4   \n",
      "19             20                        3   \n",
      "20             21                        4   \n",
      "21             22                        3   \n",
      "22             23                        3   \n",
      "23             24                        3   \n",
      "24             25                        4   \n",
      "25             26                        4   \n",
      "26             27                        4   \n",
      "27             28                        4   \n",
      "28             29                        3   \n",
      "29             30                        3   \n",
      "30             31                        3   \n",
      "31             32                        3   \n",
      "32             33                        3   \n",
      "33             34                        3   \n",
      "34             35                        3   \n",
      "35             36                        3   \n",
      "36             37                        3   \n",
      "37             38                        4   \n",
      "38             39                        4   \n",
      "39             40                        3   \n",
      "40             41                        4   \n",
      "41             42                        3   \n",
      "42             43                        4   \n",
      "43             44                        3   \n",
      "44             45                        4   \n",
      "45             46                        4   \n",
      "46             47                        3   \n",
      "47             48                        3   \n",
      "48             49                        4   \n",
      "49             50                        3   \n",
      "50             51                        3   \n",
      "51             52                        3   \n",
      "52             53                        4   \n",
      "\n",
      "                                               Name  \n",
      "0                                 Ali Afzalian Mand  \n",
      "1           Assoc. Prof. Dr Anwar P.P. Abdul Majeed  \n",
      "2                    Assoc. Prof. Dr Azam Che Idris  \n",
      "3           Assoc. Prof. Dr Muhammed Basheer Jasser  \n",
      "4                    Assoc. Prof. Dr Aslina Baharum  \n",
      "5                            Dr Danish Mahmood Khan  \n",
      "6                         Dr David Olayemi Alebiosu  \n",
      "7                            Dr Faris Syahmi Samidi  \n",
      "8                                 Dr Farrukh Hassan  \n",
      "9                                  Dr Hadyan Hafizh  \n",
      "10                       Dr Javid Iqbal Thirupattur  \n",
      "11                           Dr Mohd Firdaus Roslan  \n",
      "12                       Dr Samuel Mofoluwa Ajibade  \n",
      "13  Dr Sathishkumar Veerappampalayam Easwaramoorthy  \n",
      "14                                  Dr Teoh Yun Xin  \n",
      "15                          Nurul Aiman Abdul Rahim  \n",
      "16                      Prof. Angela Lee Siew Hoong  \n",
      "17                                Prof. Chua Hui Na  \n",
      "18                       Assoc. Prof. Dr Saad Aslam  \n",
      "19             Assoc. Prof. Dr Selina Low Yeh Ching  \n",
      "20        Assoc. Prof. Dr Sami Salama Hussen Hajjaj  \n",
      "21                       Assoc. Prof. Dr Lee Yun Li  \n",
      "22                            Charis Kwan Shwu Chen  \n",
      "23                               Dr Aaliya Sarfaraz  \n",
      "24                       Dr Ahmad Sahban Rafsanjani  \n",
      "25                             Dr Azizzeanna Hassan  \n",
      "26                         Dr Brandon Khoo Boo Guan  \n",
      "27                                  Dr Chew Moi Tin  \n",
      "28                                 Dr Chin Teck Min  \n",
      "29                                Dr Ghulam Murtaza  \n",
      "30                               Dr Maisarah Mansor  \n",
      "31                                Dr Mehran Behjati  \n",
      "32                             Dr Melody Tan Shi Ai  \n",
      "33                           Dr Noor Hafizah Hassan  \n",
      "34                     Dr Nor Hafizah Mohamed Halip  \n",
      "35                           Dr Yawar Abbas Bangash  \n",
      "36                                        Foo Jinny  \n",
      "37                                    Lim Woan Ning  \n",
      "38                               Prof. Lau Sian Lun  \n",
      "39                            Prof. Serge Demidenko  \n",
      "40                             Prof. Lee Chien Sing  \n",
      "41                                    Pyi Phyo Aung  \n",
      "42                                    Yeap Boon Han  \n",
      "43        Assoc. Prof. Dr Ranjit Singh Sarban Singh  \n",
      "44                                Dr Tang Tiong Yew  \n",
      "45                              Prof. Yap Kian Meng  \n",
      "46                                  Dr Tan Tee Hean  \n",
      "47                   Assoc. Prof. Dr Chia Wai Chong  \n",
      "48                         Dr Richard Wong Teck Ken  \n",
      "49                                Dr Ngu War Hlaing  \n",
      "50                     Assoc. Prof. Abdul Aziz Omar  \n",
      "51                           Prof. Rosdiadee Nordin  \n",
      "52                              Prof. Liew Chee Sun  \n",
      "\n",
      "Supervisor assignments statistics saved to: results/OMA/supervisor_assignments_statistics.csv\n"
     ]
    }
   ],
   "source": [
    "from pulp import LpProblem, LpVariable, LpMaximize, lpSum, LpBinary\n",
    "\n",
    "def optimal_matching(students_df, supervisors_df, balancing_penalty_weight=0.5):\n",
    "    \n",
    "    # Create the optimization problem\n",
    "    problem = LpProblem(\"Optimal_Matching\", LpMaximize)\n",
    "\n",
    "    # Create decision variables for each student-supervisor pair\n",
    "    decision_vars = {}\n",
    "    for _, student in students_df.iterrows():\n",
    "        for _, supervisor in supervisors_df.iterrows():\n",
    "            decision_vars[(student['student_id'], supervisor['supervisor_id'])] = LpVariable(\n",
    "                f\"x_{student['student_id']}_{supervisor['supervisor_id']}\", 0, 1, LpBinary\n",
    "            )\n",
    "\n",
    "    # --- Soft Balancing Setup ---\n",
    "    num_students_total = len(students_df)\n",
    "    num_supervisors_total = len(supervisors_df)\n",
    "\n",
    "    if num_supervisors_total == 0: # Avoid division by zero\n",
    "        target_load_per_supervisor = 0\n",
    "    else:\n",
    "        target_load_per_supervisor = num_students_total / num_supervisors_total\n",
    "\n",
    "    print(f\"Target load per supervisor (for soft balancing): {target_load_per_supervisor:.2f}\")\n",
    "\n",
    "    # Auxiliary variables for deviation from target load\n",
    "    supervisor_over_target = LpVariable.dicts(\n",
    "        \"SupervisorOverTarget\",\n",
    "        [s['supervisor_id'] for _, s in supervisors_df.iterrows()],\n",
    "        lowBound=0,\n",
    "        cat='Continuous'\n",
    "    )\n",
    "    supervisor_under_target = LpVariable.dicts(\n",
    "        \"SupervisorUnderTarget\",\n",
    "        [s['supervisor_id'] for _, s in supervisors_df.iterrows()],\n",
    "        lowBound=0,\n",
    "        cat='Continuous'\n",
    "    )\n",
    "\n",
    "    # Constraints linking actual load to deviation variables\n",
    "    for _, supervisor in supervisors_df.iterrows():\n",
    "        supervisor_id = supervisor['supervisor_id']\n",
    "        actual_load_expr = lpSum(decision_vars[(student['student_id'], supervisor_id)]\n",
    "                                for _, student in students_df.iterrows())\n",
    "        \n",
    "        problem += (\n",
    "            actual_load_expr - target_load_per_supervisor ==\n",
    "            supervisor_over_target[supervisor_id] - supervisor_under_target[supervisor_id],\n",
    "            f\"Define_Deviation_Supervisor_{supervisor_id}\"\n",
    "        )\n",
    "\n",
    "    # Objective function with prioritized programme preferences\n",
    "    problem += (\n",
    "        lpSum(\n",
    "            decision_vars[(student['student_id'], supervisor['supervisor_id'])] * (\n",
    "                # Programme preference weighting (higher weights to prioritize)\n",
    "                (10 if student.get('programme', '') in supervisor['Preferred Programme for Supervision (1st Choice)']  or \"No Preference\" in supervisor['Preferred Programme for Supervision (1st Choice)'] else\n",
    "                5 if student.get('programme', '') in supervisor['Preferred Programme for Supervision (2nd Choice)'] or \"No Preference\" in supervisor['Preferred Programme for Supervision (2nd Choice)'] else 0) +\n",
    "                # Topic preference weighting (lower weights relative to programme)\n",
    "                (2 * sum(1 for topic in safe_list(student['Gemini_Positive_Topics_Str'])\n",
    "                        if topic in safe_list(supervisor['standardised Topics']))) -\n",
    "                1 * sum(1 for topic in safe_list(student['Gemini_Negative_Topics_Str'])\n",
    "                        if topic in safe_list(supervisor['standardised Topics']))\n",
    "            )\n",
    "            for _, student in students_df.iterrows()\n",
    "            for _, supervisor in supervisors_df.iterrows()\n",
    "            \n",
    "        )\n",
    "        # Penalty: discourage supervisors from having too many students\n",
    "        - balancing_penalty_weight * lpSum(\n",
    "            supervisor_over_target[s['supervisor_id']] + supervisor_under_target[s['supervisor_id']]\n",
    "            for _, s in supervisors_df.iterrows()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Constraint: Each student is assigned to exactly one supervisor\n",
    "    for _, student in students_df.iterrows():\n",
    "        problem += lpSum(\n",
    "            decision_vars[(student['student_id'], supervisor['supervisor_id'])]\n",
    "            for _, supervisor in supervisors_df.iterrows()\n",
    "        ) == 1\n",
    "\n",
    "    # Constraint: Each supervisor does not exceed their capacity\n",
    "    for _, supervisor in supervisors_df.iterrows():\n",
    "        capacity = supervisor.get('capacity', 5)  # Default capacity of 5\n",
    "        problem += lpSum(\n",
    "            decision_vars[(student['student_id'], supervisor['supervisor_id'])]\n",
    "            for _, student in students_df.iterrows()\n",
    "        ) <= capacity\n",
    "\n",
    "    # Solve the problem\n",
    "    problem.solve()\n",
    "\n",
    "    # Extract and display results with detailed matching information\n",
    "    assignments = []\n",
    "    for _, student in students_df.iterrows():\n",
    "        for _, supervisor in supervisors_df.iterrows():\n",
    "            if decision_vars[(student['student_id'], supervisor['supervisor_id'])].value() == 1:\n",
    "                programme_match_type = (\n",
    "                    \"First Choice\" if (student.get('programme', '') in supervisor['Preferred Programme for Supervision (1st Choice)'] or \"No Preference\" in supervisor['Preferred Programme for Supervision (1st Choice)']) else\n",
    "                    \"Second Choice\" if (student.get('programme', '') in supervisor['Preferred Programme for Supervision (2nd Choice)'] or \"No Preference\" in supervisor['Preferred Programme for Supervision (2nd Choice)']) else\n",
    "                    \"No Match\"\n",
    "                )\n",
    "                matching_topics = [topic for topic in safe_list(student['Gemini_Positive_Topics_Str'])\n",
    "                                if topic in safe_list(supervisor['standardised Topics'])]\n",
    "                conflicting_topics = [topic for topic in safe_list(student['Gemini_Negative_Topics_Str'])\n",
    "                                    if topic in safe_list(supervisor['standardised Topics'])]\n",
    "                assignments.append({\n",
    "                    'student_id': student['student_id'],\n",
    "                    'supervisor_id': supervisor['supervisor_id'],\n",
    "                    'supervisor_name': supervisor['Name'],\n",
    "                    'programme_match': programme_match_type,\n",
    "                    'matching_topics': matching_topics,\n",
    "                    'conflicting_topics': conflicting_topics,\n",
    "                    'match_score': (\n",
    "                        10 if programme_match_type == \"First Choice\" else\n",
    "                        5 if programme_match_type == \"Second Choice\" else\n",
    "                        0\n",
    "                    ) + (2 * len(matching_topics)) - len(conflicting_topics)\n",
    "                })\n",
    "\n",
    "    # Convert assignments to DataFrame for better display\n",
    "    assignments_df = pd.DataFrame(assignments)\n",
    "    print(\"\\nOptimal Assignments:\")\n",
    "    print(assignments_df)\n",
    "\n",
    "    # Calculate and display statistics\n",
    "    print(\"\\nAssignment Statistics:\")\n",
    "    print(f\"Total assignments: {len(assignments)}\")\n",
    "    print(\"\\nProgramme Matching Distribution:\")\n",
    "    print(assignments_df['programme_match'].value_counts())\n",
    "    print(f\"\\nAverage matching topics: {assignments_df['matching_topics'].apply(len).mean():.2f}\")\n",
    "    print(f\"Average conflicting topics: {assignments_df['conflicting_topics'].apply(len).mean():.2f}\")\n",
    "    print(f\"Average match score: {assignments_df['match_score'].mean():.2f}\")\n",
    "    print(f\"Standard Deviation of match scores: {assignments_df['match_score'].std():.2f}\")\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    assignments_output_path = f\"results\\\\OMA\\\\optimal_student_supervisor_assignments_{balancing_penalty_weight}.csv\"\n",
    "    assignments_df.to_csv(assignments_output_path, index=False)\n",
    "    print(f\"\\nOptimal assignments saved to: {assignments_output_path}\")\n",
    "\n",
    "    # Analyse how many students were assigned to each supervisor\n",
    "    supervisor_assignments = assignments_df.groupby('supervisor_id').size().reset_index(name='assigned_students_count')\n",
    "    supervisor_assignments = supervisor_assignments.merge(supervisors_df[['supervisor_id', 'Name']], on='supervisor_id', how='left')\n",
    "    # Average number of students assigned per supervisor\n",
    "    average_students_per_supervisor = supervisor_assignments['assigned_students_count'].mean()\n",
    "    print(f\"\\nAverage number of students assigned per supervisor: {average_students_per_supervisor:.2f}\")\n",
    "    print(f\"Standard Deviation of students assigned per supervisor: {supervisor_assignments['assigned_students_count'].std():.2f}\")\n",
    "    print(\"\\nSupervisor Assignments Count:\")\n",
    "    print(supervisor_assignments)\n",
    "\n",
    "    match_counts = assignments_df['programme_match'].value_counts()\n",
    "\n",
    "    # Save statistics to a CSV file\n",
    "    stats_file = f\"results/OMA/supervisor_assignments_statistics.csv\"\n",
    "    # Use the average match score, standard deviation, and average students per supervisor\n",
    "    new_row = pd.DataFrame({\n",
    "        'Balancing Penalty Weight': [balancing_penalty_weight],\n",
    "        'Total Assignments': [len(assignments)],\n",
    "        'Total Match Score': [assignments_df['match_score'].sum()],\n",
    "        'Average Match Score': [assignments_df['match_score'].mean()],\n",
    "        'Standard Deviation of Match Scores': [assignments_df['match_score'].std()],\n",
    "        'Average Students per Supervisor': [average_students_per_supervisor],\n",
    "        'Standard Deviation of Students per Supervisor': [supervisor_assignments['assigned_students_count'].std()],\n",
    "        'First Choice': [match_counts.get(\"First Choice\", 0)],\n",
    "        'Second Choice': [match_counts.get(\"Second Choice\", 0)],\n",
    "        'No Match': [match_counts.get(\"No Match\", 0)],\n",
    "    })\n",
    "    # Add dataframe to CSV, append the results\n",
    "    try:\n",
    "        stats_df = pd.read_csv(stats_file)\n",
    "        stats_df = pd.concat([stats_df, new_row], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        stats_df = new_row\n",
    "    \n",
    "    stats_df.to_csv(stats_file, index=False)\n",
    "    print(f\"\\nSupervisor assignments statistics saved to: {stats_file}\")\n",
    "    \n",
    "balancing_penalty_weight = [10, 100, 1000, 10000, 100000]\n",
    "for weight in balancing_penalty_weight:\n",
    "    print(f\"\\nRunning optimal matching with balancing penalty weight: {weight}\")\n",
    "    optimal_matching(students_df, supervisors_df, weight)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
