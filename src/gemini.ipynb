{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68625e04",
   "metadata": {},
   "source": [
    "## USE GEMINI TO LABEL STUDENT PREFERENCES ACCORDING TO TOPICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff9b509",
   "metadata": {},
   "source": [
    "Import supervisor list and remove duplicate topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61e3c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data/supervisors_list.csv\n",
    "import csv\n",
    "\n",
    "def import_supervisors(file_path):\n",
    "    supervisors = []\n",
    "    try:\n",
    "        with open(file_path, mode='r', encoding='utf-8') as file:\n",
    "            csv_reader = csv.DictReader(file)\n",
    "            for row in csv_reader:\n",
    "                supervisors.append(row)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading the file: {e}\")\n",
    "    return supervisors  \n",
    "\n",
    "# Convert supervisors to a PD DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "def supervisors_to_dataframe(supervisors_csv):\n",
    "    try:\n",
    "        df = pd.DataFrame(supervisors_csv)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while converting to DataFrame: {e}\")\n",
    "        return None \n",
    "    \n",
    "def combine_expertise_topics(row, expertise_columns):\n",
    "    \"\"\"Helper function to combine topics from multiple expertise areas\"\"\"\n",
    "    all_topics = []\n",
    "    for col in expertise_columns:\n",
    "        if row[col]:\n",
    "            # Handle if input is already a list or string\n",
    "            topics = row[col] if isinstance(row[col], list) else eval(str(row[col]))\n",
    "            # Clean each topic in the list\n",
    "            cleaned_topics = [t.strip() for t in topics if t.strip()]\n",
    "            all_topics.extend(cleaned_topics)\n",
    "    # Remove duplicates while preserving order\n",
    "    unique_topics = list(dict.fromkeys(all_topics))\n",
    "    return ', '.join(unique_topics)\n",
    "\n",
    "# Generate supervisor ID and a randomised capacity\n",
    "# Add a 'topics' column that is baed on the 'Expertise Area 1', 'Expertise Area 2', and 'Expertise Area 3' columns\n",
    "def generate_supervisor_data(supervisors_df):\n",
    "    if supervisors_df is None or supervisors_df.empty:\n",
    "        print(\"No data to process.\")\n",
    "        return None\n",
    "    \n",
    "    # Generate supervisor ID\n",
    "    supervisors_df['supervisor_id'] = range(1, len(supervisors_df) + 1)\n",
    "    \n",
    "    # Randomised capacity (for example, between 1 and 5)\n",
    "    import random\n",
    "    supervisors_df['capacity'] = [random.randint(3, 10) for _ in range(len(supervisors_df))]\n",
    "    \n",
    "    # Combine expertise areas into a single 'topics' column\n",
    "    expertise_columns = ['Expertise Area 1', 'Expertise Area 2', 'Expertise Area 3']\n",
    "    supervisors_df['topics'] = supervisors_df.apply(\n",
    "        lambda x: combine_expertise_topics(x, expertise_columns), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return supervisors_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef63c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>Preferred Programme for Supervision (1st Choice)</th>\n",
       "      <th>Preferred Programme for Supervision (2nd Choice)</th>\n",
       "      <th>Expertise Area 1</th>\n",
       "      <th>Expertise Area 2</th>\n",
       "      <th>Expertise Area 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali Afzalian Mand</td>\n",
       "      <td>DDSAI</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>No Preference</td>\n",
       "      <td>[Machine Learning Theory]</td>\n",
       "      <td>[AI for Healthcare]</td>\n",
       "      <td>[Deep Learning, Neural Networks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assoc. Prof. Dr Anwar P.P. Abdul Majeed</td>\n",
       "      <td>DDSAI</td>\n",
       "      <td>BSDA</td>\n",
       "      <td>BCS / BSE / BIT</td>\n",
       "      <td>[Machine Learning, Deep Learning]</td>\n",
       "      <td>[Data Analytics]</td>\n",
       "      <td>[Robotics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assoc. Prof. Dr Azam Che Idris</td>\n",
       "      <td>DDSAI</td>\n",
       "      <td>BSDA</td>\n",
       "      <td>BCS / BSE / BIT</td>\n",
       "      <td>[DEEP LEARNING, MACHINE LEARNING]</td>\n",
       "      <td>[TIME SERIES ANALYSIS]</td>\n",
       "      <td>[COMPUTER VISION]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assoc. Prof. Dr Muhammed Basheer Jasser</td>\n",
       "      <td>DDSAI</td>\n",
       "      <td>BCS / BSE / BIT</td>\n",
       "      <td>BSDA</td>\n",
       "      <td>[Machine Learning, Artificial Intelligence]</td>\n",
       "      <td>[Swarm and Evolutionary Computing]</td>\n",
       "      <td>[Software Engineering, Software Modeling]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc. Prof. Dr Aslina Baharum</td>\n",
       "      <td>DDSAI</td>\n",
       "      <td>BCS / BSE / BIT</td>\n",
       "      <td>BSDA</td>\n",
       "      <td>[AI-UX, UX/UI Research &amp; Design, HCI, Interact...</td>\n",
       "      <td>[Software Engineering &amp; Development, Informati...</td>\n",
       "      <td>[Information and Communication Technology (ICT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name Department  \\\n",
       "0                        Ali Afzalian Mand      DDSAI   \n",
       "1  Assoc. Prof. Dr Anwar P.P. Abdul Majeed      DDSAI   \n",
       "2           Assoc. Prof. Dr Azam Che Idris      DDSAI   \n",
       "3  Assoc. Prof. Dr Muhammed Basheer Jasser      DDSAI   \n",
       "4           Assoc. Prof. Dr Aslina Baharum      DDSAI   \n",
       "\n",
       "  Preferred Programme for Supervision (1st Choice)  \\\n",
       "0                                    No Preference   \n",
       "1                                             BSDA   \n",
       "2                                             BSDA   \n",
       "3                                  BCS / BSE / BIT   \n",
       "4                                  BCS / BSE / BIT   \n",
       "\n",
       "  Preferred Programme for Supervision (2nd Choice)  \\\n",
       "0                                    No Preference   \n",
       "1                                  BCS / BSE / BIT   \n",
       "2                                  BCS / BSE / BIT   \n",
       "3                                             BSDA   \n",
       "4                                             BSDA   \n",
       "\n",
       "                                    Expertise Area 1  \\\n",
       "0                          [Machine Learning Theory]   \n",
       "1                  [Machine Learning, Deep Learning]   \n",
       "2                  [DEEP LEARNING, MACHINE LEARNING]   \n",
       "3        [Machine Learning, Artificial Intelligence]   \n",
       "4  [AI-UX, UX/UI Research & Design, HCI, Interact...   \n",
       "\n",
       "                                    Expertise Area 2  \\\n",
       "0                                [AI for Healthcare]   \n",
       "1                                   [Data Analytics]   \n",
       "2                             [TIME SERIES ANALYSIS]   \n",
       "3                 [Swarm and Evolutionary Computing]   \n",
       "4  [Software Engineering & Development, Informati...   \n",
       "\n",
       "                                    Expertise Area 3  \n",
       "0                   [Deep Learning, Neural Networks]  \n",
       "1                                         [Robotics]  \n",
       "2                                  [COMPUTER VISION]  \n",
       "3          [Software Engineering, Software Modeling]  \n",
       "4  [Information and Communication Technology (ICT...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 116 unique expertise terms to standardize:\n",
      "['AI', 'AI applications in Robotics', 'AI for Healthcare', 'AI-UX', 'AR', 'Agentic AI', 'Antenna Design', 'Application Development', 'Application development', 'Applied AI', 'Applied Generative AI', 'Applied Machine Learning', 'Applied machine learning', 'Artificial Intelligence', 'Automated Test and Measurement Systems', 'Battery Energy Storage Management', 'Big Data Analysis', 'Blockchain', 'COMPUTER VISION', 'Chatbots', 'Cloud Computing', 'Clustering Algorithms & Optimization', 'Commercial Projects', 'Computational Intelligence', 'Computer Engineering', 'Computer Graphic', 'Computer Networking', 'Computer Networks', 'Computer Science', 'Computer Vision', 'Computer Vision & Image Processing', 'Computing study with qualitative & quantitative data (survey,interview)', 'Cybersecurity', 'DEEP LEARNING', 'Data Analytics', 'Data Mining', 'Databases', 'Deep Learning', 'Deep learning', 'Development', 'Digital Image Processing', 'Distributed System', 'Distributed haptics', 'E-commerce games', 'Electronics', 'Embedded System', 'Embedded System Development', 'Embedded system applications', 'Embeded Systems', 'Environment', 'Extended reality (VR,AR,MR)', 'Fiber Optic Sensor', 'GenAI', 'Generative AI Usage Ethics', 'Green computing', 'HCI', 'High-speed computer and Telecommunications networks', 'Image Processing', 'Image and computer vision', 'Industrial IoT', 'Information Security', 'Information System', 'Information Visualization & Analytics', 'Information and Communication Technology (ICT)/ Information Technology (IT)/ Multimedia/ Information System (IS)', 'Interaction Design', 'Internet of Things (IoT)', 'IoT', 'IoT Applications', 'MACHINE LEARNING', 'Machine', 'Machine Learning', 'Machine Learning Theory', 'Machine Learning\\\\Deep learning', 'Machine learning', 'Mining', 'Mixed Reality', 'Mobile Application Development', 'Mobile Cellular Networks', 'Nanomaterial for Ultrashort Fiber Laser', 'Natural Language Processing', 'Network', 'Network Coding', 'Network Security', 'Network architectures and protocols', 'Neural Networks', 'Neuroscience', 'Operational optimisation for sustainability', 'Pattern Recognition', 'Photonic Devices', 'Product/Service Design', 'Qualitative study', 'Renewable Energy System Management', 'Robotics', 'Signal Processing', 'Smart transportation system', 'Software Engineering', 'Software Engineering & Development', 'Software Modeling', 'Statistical methods in data science', 'Sustainable smart city', 'Swarm and Evolutionary Computing', 'TIME SERIES ANALYSIS', 'Time Series Analysis', 'TinyML', 'UI and UX', 'UX/UI Research & Design', 'Ultrasound Indoor Localization', 'VR', 'Wireless Communication', 'Wireless Networks', 'deep learning', 'distributed systems', 'health', 'mobile development', 'open on data analytics', 'signal processing']\n",
      "Sending request to Gemini API...\n",
      "\n",
      "--- Standardization Map from Gemini (Review this carefully!) ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"AI\": \"Artificial Intelligence\",\n",
       "  \"AI applications in Robotics\": \"AI in Robotics\",\n",
       "  \"AI for Healthcare\": \"AI in Healthcare\",\n",
       "  \"AI-UX\": \"AI-UX\",\n",
       "  \"AR\": \"Augmented Reality\",\n",
       "  \"Agentic AI\": \"Agentic AI\",\n",
       "  \"Antenna Design\": \"Antenna Design\",\n",
       "  \"Application Development\": \"Application Development\",\n",
       "  \"Application development\": \"Application Development\",\n",
       "  \"Applied AI\": \"Applied AI\",\n",
       "  \"Applied Generative AI\": \"Applied Generative AI\",\n",
       "  \"Applied Machine Learning\": \"Applied Machine Learning\",\n",
       "  \"Applied machine learning\": \"Applied Machine Learning\",\n",
       "  \"Artificial Intelligence\": \"Artificial Intelligence\",\n",
       "  \"Automated Test and Measurement Systems\": \"Automated Test and Measurement Systems\",\n",
       "  \"Battery Energy Storage Management\": \"Battery Energy Storage Management\",\n",
       "  \"Big Data Analysis\": \"Big Data Analysis\",\n",
       "  \"Blockchain\": \"Blockchain\",\n",
       "  \"COMPUTER VISION\": \"Computer Vision\",\n",
       "  \"Chatbots\": \"Chatbots\",\n",
       "  \"Cloud Computing\": \"Cloud Computing\",\n",
       "  \"Clustering Algorithms & Optimization\": \"Clustering Algorithms & Optimization\",\n",
       "  \"Commercial Projects\": \"Commercial Projects\",\n",
       "  \"Computational Intelligence\": \"Computational Intelligence\",\n",
       "  \"Computer Engineering\": \"Computer Engineering\",\n",
       "  \"Computer Graphic\": \"Computer Graphics\",\n",
       "  \"Computer Networking\": \"Computer Networking\",\n",
       "  \"Computer Networks\": \"Computer Networks\",\n",
       "  \"Computer Science\": \"Computer Science\",\n",
       "  \"Computer Vision\": \"Computer Vision\",\n",
       "  \"Computer Vision & Image Processing\": \"Computer Vision\",\n",
       "  \"Computing study with qualitative & quantitative data (survey,interview)\": \"Data Analysis (Qualitative & Quantitative)\",\n",
       "  \"Cybersecurity\": \"Cybersecurity\",\n",
       "  \"DEEP LEARNING\": \"Deep Learning\",\n",
       "  \"Data Analytics\": \"Data Analytics\",\n",
       "  \"Data Mining\": \"Data Mining\",\n",
       "  \"Databases\": \"Databases\",\n",
       "  \"Deep Learning\": \"Deep Learning\",\n",
       "  \"Deep learning\": \"Deep Learning\",\n",
       "  \"Development\": \"Software Development\",\n",
       "  \"Digital Image Processing\": \"Image Processing\",\n",
       "  \"Distributed System\": \"Distributed Systems\",\n",
       "  \"Distributed haptics\": \"Distributed Haptics\",\n",
       "  \"E-commerce games\": \"E-commerce Games\",\n",
       "  \"Electronics\": \"Electronics\",\n",
       "  \"Embedded System\": \"Embedded Systems\",\n",
       "  \"Embedded System Development\": \"Embedded Systems Development\",\n",
       "  \"Embedded system applications\": \"Embedded Systems Applications\",\n",
       "  \"Embeded Systems\": \"Embedded Systems\",\n",
       "  \"Environment\": \"Environment\",\n",
       "  \"Extended reality (VR,AR,MR)\": \"Extended Reality\",\n",
       "  \"Fiber Optic Sensor\": \"Fiber Optic Sensor\",\n",
       "  \"GenAI\": \"Generative AI\",\n",
       "  \"Generative AI Usage Ethics\": \"Generative AI Ethics\",\n",
       "  \"Green computing\": \"Green Computing\",\n",
       "  \"HCI\": \"Human-Computer Interaction\",\n",
       "  \"High-speed computer and Telecommunications networks\": \"High-Speed Networks\",\n",
       "  \"Image Processing\": \"Image Processing\",\n",
       "  \"Image and computer vision\": \"Computer Vision\",\n",
       "  \"Industrial IoT\": \"Industrial IoT\",\n",
       "  \"Information Security\": \"Information Security\",\n",
       "  \"Information System\": \"Information Systems\",\n",
       "  \"Information Visualization & Analytics\": \"Information Visualization & Analytics\",\n",
       "  \"Information and Communication Technology (ICT)/ Information Technology (IT)/ Multimedia/ Information System (IS)\": \"Information Technology\",\n",
       "  \"Interaction Design\": \"Interaction Design\",\n",
       "  \"Internet of Things (IoT)\": \"Internet of Things\",\n",
       "  \"IoT\": \"Internet of Things\",\n",
       "  \"IoT Applications\": \"IoT Applications\",\n",
       "  \"MACHINE LEARNING\": \"Machine Learning\",\n",
       "  \"Machine\": \"Machine Learning\",\n",
       "  \"Machine Learning\": \"Machine Learning\",\n",
       "  \"Machine Learning Theory\": \"Machine Learning Theory\",\n",
       "  \"Machine Learning\\\\Deep learning\": \"Deep Learning\",\n",
       "  \"Machine learning\": \"Machine Learning\",\n",
       "  \"Mining\": \"Mining\",\n",
       "  \"Mixed Reality\": \"Mixed Reality\",\n",
       "  \"Mobile Application Development\": \"Mobile Application Development\",\n",
       "  \"Mobile Cellular Networks\": \"Mobile Networks\",\n",
       "  \"Nanomaterial for Ultrashort Fiber Laser\": \"Nanomaterials\",\n",
       "  \"Natural Language Processing\": \"Natural Language Processing\",\n",
       "  \"Network\": \"Computer Networks\",\n",
       "  \"Network Coding\": \"Network Coding\",\n",
       "  \"Network Security\": \"Network Security\",\n",
       "  \"Network architectures and protocols\": \"Network Protocols\",\n",
       "  \"Neural Networks\": \"Neural Networks\",\n",
       "  \"Neuroscience\": \"Neuroscience\",\n",
       "  \"Operational optimisation for sustainability\": \"Sustainability Optimization\",\n",
       "  \"Pattern Recognition\": \"Pattern Recognition\",\n",
       "  \"Photonic Devices\": \"Photonic Devices\",\n",
       "  \"Product/Service Design\": \"Product/Service Design\",\n",
       "  \"Qualitative study\": \"Qualitative Research\",\n",
       "  \"Renewable Energy System Management\": \"Renewable Energy Management\",\n",
       "  \"Robotics\": \"Robotics\",\n",
       "  \"Signal Processing\": \"Signal Processing\",\n",
       "  \"Smart transportation system\": \"Smart Transportation\",\n",
       "  \"Software Engineering\": \"Software Engineering\",\n",
       "  \"Software Engineering & Development\": \"Software Engineering\",\n",
       "  \"Software Modeling\": \"Software Modeling\",\n",
       "  \"Statistical methods in data science\": \"Statistical Data Analysis\",\n",
       "  \"Sustainable smart city\": \"Sustainable Smart Cities\",\n",
       "  \"Swarm and Evolutionary Computing\": \"Evolutionary Computing\",\n",
       "  \"TIME SERIES ANALYSIS\": \"Time Series Analysis\",\n",
       "  \"Time Series Analysis\": \"Time Series Analysis\",\n",
       "  \"TinyML\": \"TinyML\",\n",
       "  \"UI and UX\": \"UI/UX Design\",\n",
       "  \"UX/UI Research & Design\": \"UI/UX Design\",\n",
       "  \"Ultrasound Indoor Localization\": \"Indoor Localization\",\n",
       "  \"VR\": \"Virtual Reality\",\n",
       "  \"Wireless Communication\": \"Wireless Communication\",\n",
       "  \"Wireless Networks\": \"Wireless Networks\",\n",
       "  \"deep learning\": \"Deep Learning\",\n",
       "  \"distributed systems\": \"Distributed Systems\",\n",
       "  \"health\": \"Health\",\n",
       "  \"mobile development\": \"Mobile Development\",\n",
       "  \"open on data analytics\": \"Data Analytics\",\n",
       "  \"signal processing\": \"Signal Processing\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying standardization map to DataFrame...\n",
      "0                             [Machine Learning Theory]\n",
      "1                     [Machine Learning, Deep Learning]\n",
      "2                     [Deep Learning, Machine Learning]\n",
      "3           [Machine Learning, Artificial Intelligence]\n",
      "4     [AI-UX, UI/UX Design, Human-Computer Interacti...\n",
      "5                   [Neuroscience, Health, Environment]\n",
      "6                     [Deep Learning, Machine Learning]\n",
      "7                                          [Applied AI]\n",
      "8                                     [Computer Vision]\n",
      "9                                          [Applied AI]\n",
      "10    [Mixed Reality, Augmented Reality, Virtual Rea...\n",
      "11                                         [Applied AI]\n",
      "12                                   [Machine Learning]\n",
      "13                                        [Data Mining]\n",
      "14                            [Artificial Intelligence]\n",
      "15    [Virtual Reality, Augmented Reality, Computer ...\n",
      "16                                                [AI ]\n",
      "17    [Applied Machine Learning, Deep Learning, Arti...\n",
      "18    [Wireless Networks, Wireless Communication, Mo...\n",
      "19                                     [Data Analytics]\n",
      "20              [Applied AI, Generative AI, Agentic AI]\n",
      "21                                    [Computer Vision]\n",
      "22                                         [Applied AI]\n",
      "23                                        [Blockchain ]\n",
      "24                                      [Cybersecurity]\n",
      "25                                [Information System ]\n",
      "26                                    [Computer Vision]\n",
      "27                                   [Embedded Systems]\n",
      "28                               [Software Development]\n",
      "29                    [Machine Learning, Deep Learning]\n",
      "30                                   [Photonic Devices]\n",
      "31                                  [Computer Networks]\n",
      "32                                     [Data Analytics]\n",
      "33                                [Information Systems]\n",
      "34                                         [Applied AI]\n",
      "35                                  [Computer Networks]\n",
      "36                                  [Big Data Analysis]\n",
      "37                                   [Extended Reality]\n",
      "38                                    [Green Computing]\n",
      "39                  [Computer Engineering, Electronics]\n",
      "40                                  [E-commerce games ]\n",
      "41                                   [Embedded Systems]\n",
      "42                               [Software Development]\n",
      "43                        [Renewable Energy Management]\n",
      "44                  [Applied Generative AI, Applied AI]\n",
      "45                                [Distributed Haptics]\n",
      "46                                 [Mobile Development]\n",
      "47                            [Application Development]\n",
      "48                               [Smart Transportation]\n",
      "49                             [Wireless Communication]\n",
      "50                                     [Data Analytics]\n",
      "51                                                   []\n",
      "52    [Distributed Systems, Internet of Things, Data...\n",
      "Name: Standardized Expertise 1, dtype: object\n",
      "0                                    [AI in Healthcare]\n",
      "1                                      [Data Analytics]\n",
      "2                                [Time Series Analysis]\n",
      "3                              [Evolutionary Computing]\n",
      "4     [Software Engineering, Information Visualizati...\n",
      "5                                       [Deep Learning]\n",
      "6                                    [Image Processing]\n",
      "7                                  [Internet of Things]\n",
      "8                     [Deep Learning, Machine Learning]\n",
      "9                                      [Industrial IoT]\n",
      "10                                               [IoT ]\n",
      "11                                     [Data Analytics]\n",
      "12                            [Artificial Intelligence]\n",
      "13                                   [Machine Learning]\n",
      "14                                   [Image Processing]\n",
      "15           [UI/UX Design, Human-Computer Interaction]\n",
      "16                                     [Data Analytics]\n",
      "17                                                   []\n",
      "18                                   [Machine Learning]\n",
      "19                          [Statistical Data Analysis]\n",
      "20                 [AI in Robotics, Internet of Things]\n",
      "21                                   [Machine Learning]\n",
      "22                               [Software Development]\n",
      "23                                                   []\n",
      "24                                [Computer Networking]\n",
      "25                               [Qualitative Research]\n",
      "26          [Computational Intelligence, Deep Learning]\n",
      "27                                [Indoor Localization]\n",
      "28                                [Distributed Systems]\n",
      "29                                   [Image Processing]\n",
      "30                                 [Fiber Optic Sensor]\n",
      "31                            [Artificial Intelligence]\n",
      "32                                   [Machine Learning]\n",
      "33         [Data Analysis (Qualitative & Quantitative)]\n",
      "34                                     [Industrial IoT]\n",
      "35                               [Information Security]\n",
      "36                                        [Data Mining]\n",
      "37                            [Application Development]\n",
      "38                           [Applied Machine Learning]\n",
      "39                [Signal Processing, Image Processing]\n",
      "40                                           [Chatbots]\n",
      "41                                             [TinyML]\n",
      "42                                                   []\n",
      "43                  [Battery Energy Storage Management]\n",
      "44                                   [Machine Learning]\n",
      "45                                  [Network Protocols]\n",
      "46                        [Natural Language Processing]\n",
      "47                                   [Image Processing]\n",
      "48                        [Sustainability Optimization]\n",
      "49                                     [Network Coding]\n",
      "50                                                   []\n",
      "51                                                   []\n",
      "52                                                   []\n",
      "Name: Standardized Expertise 2, dtype: object\n",
      "0                [Deep Learning, Neural Networks]\n",
      "1                                      [Robotics]\n",
      "2                               [Computer Vision]\n",
      "3       [Software Engineering, Software Modeling]\n",
      "4      [Information Technology, Computer Science]\n",
      "5            [Computer Vision, Signal Processing]\n",
      "6                           [Pattern Recognition]\n",
      "7                [Mobile Application Development]\n",
      "8                          [Time Series Analysis]\n",
      "9                                 [Deep Learning]\n",
      "10                                             []\n",
      "11    [Artificial Intelligence, Machine Learning]\n",
      "12                               [Data Analytics]\n",
      "13                                             []\n",
      "14                                             []\n",
      "15                             [Machine Learning]\n",
      "16                             [Machine Learning]\n",
      "17                                             []\n",
      "18         [Clustering Algorithms & Optimization]\n",
      "19                                   [Applied AI]\n",
      "20                             [IoT Applications]\n",
      "21                               [Data Analytics]\n",
      "22                             [Machine Learning]\n",
      "23                                             []\n",
      "24                                             []\n",
      "25                                             []\n",
      "26                         [Generative AI Ethics]\n",
      "27       [Automated Test and Measurement Systems]\n",
      "28                         [Software Engineering]\n",
      "29                       [Data Analytics, Mining]\n",
      "30                                [Nanomaterials]\n",
      "31                                             []\n",
      "32                                             []\n",
      "33                                             []\n",
      "34                                             []\n",
      "35                         [Software Engineering]\n",
      "36                                   [Blockchain]\n",
      "37                             [Machine Learning]\n",
      "38                     [Sustainable Smart Cities]\n",
      "39                         [Software Engineering]\n",
      "40                                             []\n",
      "41                           [Internet of Things]\n",
      "42                                             []\n",
      "43                 [Embedded Systems Development]\n",
      "44    [Robotics, Blockchain, Commercial Projects]\n",
      "45                          [High-Speed Networks]\n",
      "46                         [Software Development]\n",
      "47                                             []\n",
      "48                [Embedded Systems Applications]\n",
      "49                               [Antenna Design]\n",
      "50                                             []\n",
      "51                                             []\n",
      "52                                             []\n",
      "Name: Standardized Expertise 3, dtype: object\n",
      "\n",
      "DataFrame with Standardized Expertise:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Expertise Area 1</th>\n",
       "      <th>Expertise Area 2</th>\n",
       "      <th>Expertise Area 3</th>\n",
       "      <th>Standardized Expertise 1</th>\n",
       "      <th>Standardized Expertise 2</th>\n",
       "      <th>Standardized Expertise 3</th>\n",
       "      <th>Standardized Topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali Afzalian Mand</td>\n",
       "      <td>[Machine Learning Theory]</td>\n",
       "      <td>[AI for Healthcare]</td>\n",
       "      <td>[Deep Learning, Neural Networks]</td>\n",
       "      <td>[Machine Learning Theory]</td>\n",
       "      <td>[AI in Healthcare]</td>\n",
       "      <td>[Deep Learning, Neural Networks]</td>\n",
       "      <td>Machine Learning Theory, AI in Healthcare, Dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Assoc. Prof. Dr Anwar P.P. Abdul Majeed</td>\n",
       "      <td>[Machine Learning, Deep Learning]</td>\n",
       "      <td>[Data Analytics]</td>\n",
       "      <td>[Robotics]</td>\n",
       "      <td>[Machine Learning, Deep Learning]</td>\n",
       "      <td>[Data Analytics]</td>\n",
       "      <td>[Robotics]</td>\n",
       "      <td>Machine Learning, Deep Learning, Data Analytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assoc. Prof. Dr Azam Che Idris</td>\n",
       "      <td>[DEEP LEARNING, MACHINE LEARNING]</td>\n",
       "      <td>[TIME SERIES ANALYSIS]</td>\n",
       "      <td>[COMPUTER VISION]</td>\n",
       "      <td>[Deep Learning, Machine Learning]</td>\n",
       "      <td>[Time Series Analysis]</td>\n",
       "      <td>[Computer Vision]</td>\n",
       "      <td>Deep Learning, Machine Learning, Time Series A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assoc. Prof. Dr Muhammed Basheer Jasser</td>\n",
       "      <td>[Machine Learning, Artificial Intelligence]</td>\n",
       "      <td>[Swarm and Evolutionary Computing]</td>\n",
       "      <td>[Software Engineering, Software Modeling]</td>\n",
       "      <td>[Machine Learning, Artificial Intelligence]</td>\n",
       "      <td>[Evolutionary Computing]</td>\n",
       "      <td>[Software Engineering, Software Modeling]</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Evo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assoc. Prof. Dr Aslina Baharum</td>\n",
       "      <td>[AI-UX, UX/UI Research &amp; Design, HCI, Interact...</td>\n",
       "      <td>[Software Engineering &amp; Development, Informati...</td>\n",
       "      <td>[Information and Communication Technology (ICT...</td>\n",
       "      <td>[AI-UX, UI/UX Design, Human-Computer Interacti...</td>\n",
       "      <td>[Software Engineering, Information Visualizati...</td>\n",
       "      <td>[Information Technology, Computer Science]</td>\n",
       "      <td>AI-UX, UI/UX Design, Human-Computer Interactio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name  \\\n",
       "0                        Ali Afzalian Mand   \n",
       "1  Assoc. Prof. Dr Anwar P.P. Abdul Majeed   \n",
       "2           Assoc. Prof. Dr Azam Che Idris   \n",
       "3  Assoc. Prof. Dr Muhammed Basheer Jasser   \n",
       "4           Assoc. Prof. Dr Aslina Baharum   \n",
       "\n",
       "                                    Expertise Area 1  \\\n",
       "0                          [Machine Learning Theory]   \n",
       "1                  [Machine Learning, Deep Learning]   \n",
       "2                  [DEEP LEARNING, MACHINE LEARNING]   \n",
       "3        [Machine Learning, Artificial Intelligence]   \n",
       "4  [AI-UX, UX/UI Research & Design, HCI, Interact...   \n",
       "\n",
       "                                    Expertise Area 2  \\\n",
       "0                                [AI for Healthcare]   \n",
       "1                                   [Data Analytics]   \n",
       "2                             [TIME SERIES ANALYSIS]   \n",
       "3                 [Swarm and Evolutionary Computing]   \n",
       "4  [Software Engineering & Development, Informati...   \n",
       "\n",
       "                                    Expertise Area 3  \\\n",
       "0                   [Deep Learning, Neural Networks]   \n",
       "1                                         [Robotics]   \n",
       "2                                  [COMPUTER VISION]   \n",
       "3          [Software Engineering, Software Modeling]   \n",
       "4  [Information and Communication Technology (ICT...   \n",
       "\n",
       "                            Standardized Expertise 1  \\\n",
       "0                          [Machine Learning Theory]   \n",
       "1                  [Machine Learning, Deep Learning]   \n",
       "2                  [Deep Learning, Machine Learning]   \n",
       "3        [Machine Learning, Artificial Intelligence]   \n",
       "4  [AI-UX, UI/UX Design, Human-Computer Interacti...   \n",
       "\n",
       "                            Standardized Expertise 2  \\\n",
       "0                                 [AI in Healthcare]   \n",
       "1                                   [Data Analytics]   \n",
       "2                             [Time Series Analysis]   \n",
       "3                           [Evolutionary Computing]   \n",
       "4  [Software Engineering, Information Visualizati...   \n",
       "\n",
       "                     Standardized Expertise 3  \\\n",
       "0            [Deep Learning, Neural Networks]   \n",
       "1                                  [Robotics]   \n",
       "2                           [Computer Vision]   \n",
       "3   [Software Engineering, Software Modeling]   \n",
       "4  [Information Technology, Computer Science]   \n",
       "\n",
       "                                 Standardized Topics  \n",
       "0  Machine Learning Theory, AI in Healthcare, Dee...  \n",
       "1  Machine Learning, Deep Learning, Data Analytic...  \n",
       "2  Deep Learning, Machine Learning, Time Series A...  \n",
       "3  Machine Learning, Artificial Intelligence, Evo...  \n",
       "4  AI-UX, UI/UX Design, Human-Computer Interactio...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardization map saved to: gemini_standardization_map.json\n",
      "Augmented DataFrame saved to CSV: supervisors_standardized_gemini.csv\n",
      "\n",
      "Unique individual standardized topic terms found across all supervisors:\n",
      "['AI', 'AI in Healthcare', 'AI in Robotics', 'AI-UX', 'Agentic AI', 'Antenna Design', 'Application Development', 'Applied AI', 'Applied Generative AI', 'Applied Machine Learning', 'Artificial Intelligence', 'Augmented Reality', 'Automated Test and Measurement Systems', 'Battery Energy Storage Management', 'Big Data Analysis', 'Blockchain', 'Chatbots', 'Cloud Computing', 'Clustering Algorithms & Optimization', 'Commercial Projects', 'Computational Intelligence', 'Computer Engineering', 'Computer Graphics', 'Computer Networking', 'Computer Networks', 'Computer Science', 'Computer Vision', 'Cybersecurity', 'Data Analysis (Qualitative & Quantitative)', 'Data Analytics', 'Data Mining', 'Databases', 'Deep Learning', 'Distributed Haptics', 'Distributed Systems', 'E-commerce games', 'Electronics', 'Embedded Systems', 'Embedded Systems Applications', 'Embedded Systems Development', 'Environment', 'Evolutionary Computing', 'Extended Reality', 'Fiber Optic Sensor', 'Generative AI', 'Generative AI Ethics', 'Green Computing', 'Health', 'High-Speed Networks', 'Human-Computer Interaction', 'Image Processing', 'Indoor Localization', 'Industrial IoT', 'Information Security', 'Information System', 'Information Systems', 'Information Technology', 'Information Visualization & Analytics', 'Interaction Design', 'Internet of Things', 'IoT', 'IoT Applications', 'Machine Learning', 'Machine Learning Theory', 'Mining', 'Mixed Reality', 'Mobile Application Development', 'Mobile Development', 'Mobile Networks', 'Nanomaterials', 'Natural Language Processing', 'Network Coding', 'Network Protocols', 'Network Security', 'Neural Networks', 'Neuroscience', 'Pattern Recognition', 'Photonic Devices', 'Product/Service Design', 'Qualitative Research', 'Renewable Energy Management', 'Robotics', 'Signal Processing', 'Smart Transportation', 'Software Development', 'Software Engineering', 'Software Modeling', 'Statistical Data Analysis', 'Sustainability Optimization', 'Sustainable Smart Cities', 'Time Series Analysis', 'TinyML', 'UI/UX Design', 'Virtual Reality', 'Wireless Communication', 'Wireless Networks']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import os\n",
    "from IPython.display import display, Markdown # For better display in notebooks\n",
    "from ast import literal_eval\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyBr8aF6h4Vp1LpwxbKtD8KvuaCfUcl-2MM'\n",
    "\n",
    "# --- Configuration ---\n",
    "# 1. Configure your Google API Key\n",
    "#    Store your API key in an environment variable GOOGLE_API_KEY\n",
    "#    In your terminal: export GOOGLE_API_KEY='your_actual_api_key'\n",
    "#    Or, less securely, for testing:\n",
    "#    GOOGLE_API_KEY = \"YOUR_API_KEY_HERE\" # Replace with your actual key\n",
    "#    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "try:\n",
    "    # Attempt to configure from environment variable\n",
    "    if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "        print(\"Warning: GOOGLE_API_KEY environment variable not set.\")\n",
    "        # Fallback or prompt if necessary, for this example we'll assume it's set or manually provided\n",
    "        # GOOGLE_API_KEY = input(\"Enter your Google API Key: \") # Example of prompting\n",
    "        # genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        # For robust scripts, handle this more gracefully.\n",
    "    genai.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
    "except Exception as e:\n",
    "    print(f\"Error configuring Gemini API: {e}\")\n",
    "    print(\"Please ensure your GOOGLE_API_KEY is correctly set.\")\n",
    "    # Exit or raise if critical\n",
    "\n",
    "# Initialize the Gemini Pro model\n",
    "# For text-only input, use gemini-pro\n",
    "# If you need to include images, use gemini-pro-vision\n",
    "try:\n",
    "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Gemini model: {e}\")\n",
    "    model = None # Ensure model is None if initialization fails\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def extract_unique_expertise_terms(df, expertise_cols):\n",
    "    \"\"\"Extracts all unique, non-empty expertise terms from specified columns.\"\"\"\n",
    "    all_terms = set()\n",
    "    for col in expertise_cols:\n",
    "        # Ensure column exists and handle potential errors if it doesn't\n",
    "        if col in df.columns:\n",
    "            # Drop NaNs\n",
    "            col_data = df[col].dropna()\n",
    "            for item in col_data:\n",
    "                # If the cell is a list, extend; if string, treat as single topic\n",
    "                if isinstance(item, list):\n",
    "                    all_terms.update([t.strip() for t in item if t and str(t).strip()])\n",
    "                else:\n",
    "                    # Try to parse string representation of list, else treat as single string\n",
    "                    try:\n",
    "                        parsed = eval(item) if isinstance(item, str) and item.startswith(\"[\") else item\n",
    "                        if isinstance(parsed, list):\n",
    "                            all_terms.update([t.strip() for t in parsed if t and str(t).strip()])\n",
    "                        else:\n",
    "                            if str(parsed).strip():\n",
    "                                all_terms.add(str(parsed).strip())\n",
    "                    except Exception:\n",
    "                        if str(item).strip():\n",
    "                            all_terms.add(str(item).strip())\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found in DataFrame.\")\n",
    "    return sorted(list(all_terms))\n",
    "\n",
    "def get_standardization_map_from_gemini(unique_terms_list):\n",
    "    \"\"\"\n",
    "    Sends a list of unique expertise terms to Gemini and asks for a standardization map.\n",
    "    Returns a dictionary: {\"original_term\": \"standardized_term\"}.\n",
    "    \"\"\"\n",
    "    if not model:\n",
    "        print(\"Gemini model not initialized. Cannot proceed.\")\n",
    "        return None\n",
    "    if not unique_terms_list:\n",
    "        print(\"No unique terms provided to standardize.\")\n",
    "        return {}\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert academic research field categorizer and data normalizer.\n",
    "    I have a list of expertise areas extracted from a dataset of supervisors.\n",
    "    Many of these terms are variations of the same concept (e.g., \"IoT\", \"Internet of Things\", \"Industrial IoT\")\n",
    "    or very closely related.\n",
    "\n",
    "    Your task is to analyze the following list of unique expertise terms and create a JSON object\n",
    "    that maps each original term to a single, consistent, standardized \"umbrella\" term.\n",
    "\n",
    "    Guidelines:\n",
    "    1. The standardized term should be a concise and commonly understood representation of the concept.\n",
    "    2. If an original term is already a good standard, it can map to itself.\n",
    "    3. Group synonymous or very similar terms under ONE standardized term. For example, if \"Machine Learning\", \"ML\", and \"Deep Learning\" are present, they might all map to \"Machine Learning\" or you might decide \"Deep Learning\" should map to \"Deep Learning\" if it's distinct enough, while \"ML\" maps to \"Machine Learning\". Use your best judgment to create meaningful umbrella terms.\n",
    "    4. The output MUST be a single JSON object where keys are the *original* expertise terms from the input list, and values are their corresponding *standardized* umbrella terms. Every term from the input list must be a key in the output JSON.\n",
    "    5. Do not include any explanatory text outside the JSON object. Just the JSON.\n",
    "\n",
    "    List of unique expertise terms:\n",
    "    {json.dumps(unique_terms_list)}\n",
    "\n",
    "    Please provide the JSON mapping:\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Sending request to Gemini API...\")\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        # Gemini API can sometimes wrap JSON in markdown backticks\n",
    "        cleaned_response_text = response.text.strip().removeprefix(\"```json\").removeprefix(\"```\").removesuffix(\"```\").strip()\n",
    "\n",
    "        # Validate and parse JSON\n",
    "        try:\n",
    "            standardization_map = json.loads(cleaned_response_text)\n",
    "            # Basic validation: ensure it's a dict\n",
    "            if not isinstance(standardization_map, dict):\n",
    "                print(\"Error: Gemini did not return a valid JSON dictionary.\")\n",
    "                print(\"Raw response:\", response.text)\n",
    "                return None\n",
    "            # Ensure all original terms are keys\n",
    "            missing_keys = [term for term in unique_terms_list if term not in standardization_map]\n",
    "            if missing_keys:\n",
    "                print(f\"Warning: Gemini's map is missing keys for: {missing_keys}\")\n",
    "                # You could add them, mapping to themselves, or raise an error\n",
    "                for key in missing_keys:\n",
    "                    standardization_map[key] = key # Default to self-mapping\n",
    "            return standardization_map\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from Gemini: {e}\")\n",
    "            print(\"Raw response text from Gemini:\")\n",
    "            print(response.text) # print the raw response for debugging\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Gemini API: {e}\")\n",
    "        if hasattr(e, 'response') and e.response: # More detailed error if available\n",
    "            print(f\"Gemini API Error Details: {e.response}\")\n",
    "        return None\n",
    "\n",
    "# --- Main Processing ---\n",
    "\n",
    "# 1. Load your CSV\n",
    "csv_file_path = 'data\\\\supervisors_list.csv' # <--- CHANGE FILENAME\n",
    "# Define expertise columns\n",
    "expertise_columns = ['Expertise Area 1', 'Expertise Area 2', 'Expertise Area 3']\n",
    "\n",
    "try:\n",
    "    supervisors_df = pd.read_csv(csv_file_path)\n",
    "    for col in expertise_columns:\n",
    "        if col not in supervisors_df.columns:\n",
    "            print(f\"Warning: Column '{col}' not found in CSV. Skipping standardization for this column.\")\n",
    "            expertise_columns.remove(col)\n",
    "        else:\n",
    "            # Ensure expertise columns are treated as lists\n",
    "            supervisors_df[col] = supervisors_df[col].apply(literal_eval)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{csv_file_path}' not found. Using dummy data for demonstration.\")\n",
    "    data = {\n",
    "        'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "        'Department': ['CS', 'CS', 'AI', 'CS', 'EE'],\n",
    "        'Preferred Programme for Supervision (1st Choice)': ['PhD CS', 'MSc AI', 'PhD AI', 'MSc DS', 'PhD EE'],\n",
    "        'Preferred Programme for Supervision (2nd Choice)': ['MSc AI', 'PhD CS', 'MSc DS', 'PhD CS', 'MSc CS'],\n",
    "        'Expertise Area 1': ['Machine Learning', 'Software Architecture', 'Natural Language Processing', 'Data Mining', 'IoT'],\n",
    "        'Expertise Area 2': ['Deep Learning', 'Agile Development', pd.NA, 'Big Data Analytics', 'Internet of Things'],\n",
    "        'Expertise Area 3': ['Computer Vision', pd.NA, 'Ethics in AI', 'Cloud Computing', 'Industrial IoT']\n",
    "    }\n",
    "    supervisors_df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame sample:\")\n",
    "display(supervisors_df.head())\n",
    "\n",
    "# 2. Extract All Unique Expertise Terms\n",
    "unique_terms = extract_unique_expertise_terms(supervisors_df, expertise_columns)\n",
    "if not unique_terms:\n",
    "    print(\"No expertise terms found to process. Exiting.\")\n",
    "    # exit() # Or handle appropriately\n",
    "else:\n",
    "    print(f\"\\nFound {len(unique_terms)} unique expertise terms to standardize:\")\n",
    "    print(unique_terms)\n",
    "\n",
    "    # 3. Get Standardization Map from Gemini (only if model initialized and terms exist)\n",
    "    standardization_dictionary = None\n",
    "    if model and unique_terms:\n",
    "        standardization_dictionary = get_standardization_map_from_gemini(unique_terms)\n",
    "\n",
    "    if standardization_dictionary:\n",
    "        print(\"\\n--- Standardization Map from Gemini (Review this carefully!) ---\")\n",
    "        # Pretty print the dictionary for review\n",
    "        display(Markdown(\"```json\\n\" + json.dumps(standardization_dictionary, indent=2) + \"\\n```\"))\n",
    "\n",
    "        # --- OPTIONAL: Manual Review & Override Step ---\n",
    "        # At this point, you could pause, let the user review the `standardization_dictionary`,\n",
    "        # make manual edits to it, and then proceed. For example:\n",
    "        # corrected_map_json = input(\"Copy, paste, and edit the map above if needed, then press Enter:\\n\")\n",
    "        # try:\n",
    "        #     standardization_dictionary = json.loads(corrected_map_json)\n",
    "        # except json.JSONDecodeError:\n",
    "        #     print(\"Invalid JSON entered for correction. Using original map.\")\n",
    "        # ---\n",
    "\n",
    "        # 4. Apply Mapping to Create Standardized Expertise Columns\n",
    "        print(\"\\nApplying standardization map to DataFrame...\")\n",
    "        for i, col_name in enumerate(expertise_columns):\n",
    "            if col_name in supervisors_df.columns:\n",
    "                standardized_col_name = f'Standardized Expertise {i+1}'\n",
    "                # Map original terms to standardized ones. If a term is not in the map (e.g., NaN originally),\n",
    "                # it will result in NaN, which is often desired.\n",
    "                # Fillna('') before mapping if you want empty strings to map to something specific,\n",
    "                # or handle it in the map itself.\n",
    "                supervisors_df[standardized_col_name] = supervisors_df[col_name].apply(\n",
    "                    lambda topics: [standardization_dictionary.get(t, t) for t in topics] if isinstance(topics, list)\n",
    "                    else [standardization_dictionary.get(str(topics), str(topics))] if pd.notna(topics) and str(topics).strip()\n",
    "                    else []\n",
    "                )\n",
    "                print(supervisors_df[standardized_col_name])\n",
    "            else:\n",
    "                print(f\"Skipping standardization for non-existent column: {col_name}\")\n",
    "\n",
    "\n",
    "        # 5. Combine Standardized Expertise into a single column\n",
    "        standardized_expertise_cols = [f'Standardized Expertise {i+1}' for i in range(len(expertise_columns)) if f'Standardized Expertise {i+1}' in supervisors_df.columns]\n",
    "\n",
    "        if standardized_expertise_cols: # only proceed if standardized columns were created\n",
    "            supervisors_df['Standardized Topics'] = supervisors_df.apply(\n",
    "                lambda x: combine_expertise_topics(x, standardized_expertise_cols),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            print(\"\\nDataFrame with Standardized Expertise:\")\n",
    "            display(supervisors_df[['Name'] + expertise_columns + standardized_expertise_cols + ['Standardized Topics']].head())\n",
    "\n",
    "            # 6. Save Outputs\n",
    "            # Save the standardization map to a JSON file\n",
    "            map_output_path = 'gemini_standardization_map.json'\n",
    "            with open(map_output_path, 'w') as f:\n",
    "                json.dump(standardization_dictionary, f, indent=4)\n",
    "            print(f\"\\nStandardization map saved to: {map_output_path}\")\n",
    "\n",
    "            # Save the augmented DataFrame to CSV\n",
    "            csv_output_path = 'supervisors_standardized_gemini.csv'\n",
    "            supervisors_df.to_csv(csv_output_path, index=False)\n",
    "            print(f\"Augmented DataFrame saved to CSV: {csv_output_path}\")\n",
    "\n",
    "            # Example: Further manipulation - unique standardized topics\n",
    "            if 'Standardized Topics' in supervisors_df.columns:\n",
    "                unique_standardized_topics_list = supervisors_df['Standardized Topics'].str.split(', ').explode().str.strip()\n",
    "                unique_standardized_topics_list = unique_standardized_topics_list[unique_standardized_topics_list != ''].unique()\n",
    "                print(\"\\nUnique individual standardized topic terms found across all supervisors:\")\n",
    "                print(sorted(list(unique_standardized_topics_list)))\n",
    "        else:\n",
    "            print(\"\\nNo standardized expertise columns were created. Skipping combination and saving of DataFrame.\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\nFailed to get standardization map from Gemini. No changes applied to DataFrame.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env_capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
